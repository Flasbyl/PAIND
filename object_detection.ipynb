{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving images with mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "image_folder = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\batch\"\n",
    "output_folder = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\labeled_regions\"\n",
    "mask_folder = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\batch\\output_grayscale_gaussian\"\n",
    "\n",
    "# Masks as file paths\n",
    "masks = {\n",
    "    \"filled_mask_below\": os.path.join(mask_folder, \"filled_mask_below.png\"),\n",
    "    \"filled_mask_above\": os.path.join(mask_folder, \"filled_mask_above.png\"),\n",
    "    \"deducted_mask_outside\": os.path.join(mask_folder, \"deducted_mask_outside.png\"),\n",
    "    \"mask_inside\": os.path.join(mask_folder, \"mask_inside.png\"),\n",
    "}\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Load and validate masks\n",
    "loaded_masks = {}\n",
    "for mask_name, mask_path in masks.items():\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if mask is None:\n",
    "        raise FileNotFoundError(f\"Mask '{mask_name}' not found at {mask_path}.\")\n",
    "    loaded_masks[mask_name] = mask\n",
    "\n",
    "# Process images\n",
    "images = sorted([img for img in os.listdir(image_folder) if img.endswith(\".jpg\")])\n",
    "\n",
    "for img_name in tqdm(images, desc=\"Processing Images\"):\n",
    "    img_path = os.path.join(image_folder, img_name)\n",
    "    image = cv2.imread(img_path)\n",
    "\n",
    "    for region_name, mask in loaded_masks.items():\n",
    "        # Ensure the mask matches the image dimensions\n",
    "        if mask.shape[:2] != image.shape[:2]:\n",
    "            mask = cv2.resize(mask, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # Apply the mask to the image\n",
    "        region = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "        # Save the region\n",
    "        region_path = os.path.join(output_folder, f\"{region_name}_{img_name}\")\n",
    "        cv2.imwrite(region_path, region)\n",
    "\n",
    "print(f\"Region-specific images saved to {output_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = {\n",
    "    \"filled_mask_below\": os.path.join(mask_folder, \"filled_mask_below.png\"),\n",
    "    \"filled_mask_above\": os.path.join(mask_folder, \"filled_mask_above.png\"),\n",
    "    \"mask_inside\": os.path.join(mask_folder, \"mask_inside.png\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "image_folder = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\labeled_regions\\inside\"\n",
    "output_analysis_folder = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\labeled_regions\\inside\\hand_detection_mediapipe\"\n",
    "os.makedirs(output_analysis_folder, exist_ok=True)\n",
    "\n",
    "# Import only required components from MediaPipe\n",
    "from mediapipe.python.solutions.hands import Hands\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "hands = Hands(static_image_mode=True, max_num_hands=2, min_detection_confidence=0.5)\n",
    "\n",
    "# Process the images\n",
    "results = []\n",
    "image_filenames = sorted([img for img in os.listdir(image_folder) if img.endswith(\".jpg\")])\n",
    "\n",
    "for img_name in tqdm(image_filenames, desc=\"Processing Images for Hand Detection\"):\n",
    "    img_path = os.path.join(image_folder, img_name)\n",
    "    image = cv2.imread(img_path)\n",
    "    if image is None:\n",
    "        continue\n",
    "\n",
    "    # Convert image to RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image with MediaPipe Hands\n",
    "    result = hands.process(image_rgb)\n",
    "\n",
    "    # Analyze results\n",
    "    hand_detected = False\n",
    "    hand_bounding_boxes = []\n",
    "\n",
    "    if result.multi_hand_landmarks:\n",
    "        hand_detected = True\n",
    "        for hand_landmarks in result.multi_hand_landmarks:\n",
    "            # Calculate bounding box\n",
    "            x_min = min([lm.x for lm in hand_landmarks.landmark]) * image.shape[1]\n",
    "            y_min = min([lm.y for lm in hand_landmarks.landmark]) * image.shape[0]\n",
    "            x_max = max([lm.x for lm in hand_landmarks.landmark]) * image.shape[1]\n",
    "            y_max = max([lm.y for lm in hand_landmarks.landmark]) * image.shape[0]\n",
    "            hand_bounding_boxes.append([int(x_min), int(y_min), int(x_max - x_min), int(y_max - y_min)])\n",
    "\n",
    "    # Save the result\n",
    "    result_entry = {\n",
    "        \"image\": img_name,\n",
    "        \"result\": \"Hand detected\" if hand_detected else \"No hand detected\",\n",
    "        \"bounding_boxes\": hand_bounding_boxes\n",
    "    }\n",
    "    results.append(result_entry)\n",
    "\n",
    "# Save results to a JSON file\n",
    "output_json_path = os.path.join(output_analysis_folder, \"hand_detection_mediapipe.json\")\n",
    "with open(output_json_path, \"w\") as json_file:\n",
    "    json.dump(results, json_file, indent=4)\n",
    "\n",
    "print(f\"Hand detection analysis saved to: {output_json_path}\")\n",
    "\n",
    "# Release MediaPipe resources\n",
    "hands.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "hand_detection_results_path = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\labeled_regions\\inside\\hand_detection_mediapipe\\hand_detection_mediapipe.json\"\n",
    "output_plot_path = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\labeled_regions\\inside\\hand_detection_timeseries.png\"\n",
    "\n",
    "# Function to extract timestamp from image name\n",
    "def extract_timestamp_from_image_name(image_name):\n",
    "    \"\"\"\n",
    "    Extracts a timestamp from an image name with the format:\n",
    "    \"prefix_YYYYMMDD_HHMMSSfff_suffix.jpg\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        timestamp_str = image_name.split('_')[2]\n",
    "        print(timestamp_str)\n",
    "        time_str = image_name.split('_')[3][:9]  # Extract HHMMSSfff\n",
    "        print(time_str)\n",
    "        print(f\"{timestamp_str[:4]}-{timestamp_str[4:6]}-{timestamp_str[6:]} {time_str[:2]}:{time_str[2:4]}:{time_str[4:6]}.{time_str[6:]}\")\n",
    "        return pd.Timestamp(f\"{time_str[:2]}:{time_str[2:4]}:{time_str[4:6]}.{time_str[6:]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting timestamp from {image_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load hand detection results\n",
    "with open(hand_detection_results_path, \"r\") as f:\n",
    "    hand_detection_results = json.load(f)\n",
    "\n",
    "# Process results to create a DataFrame\n",
    "data = []\n",
    "for entry in hand_detection_results:\n",
    "    timestamp = extract_timestamp_from_image_name(entry[\"image\"])\n",
    "    hand_detected = entry[\"result\"] == \"Hand detected\"\n",
    "    data.append({\"Timestamp\": timestamp, \"Hand Detected\": hand_detected})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Ensure timestamps are sorted\n",
    "df = df.sort_values(\"Timestamp\").reset_index(drop=True)\n",
    "\n",
    "# Create a time series plot\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(df[\"Timestamp\"], df[\"Hand Detected\"].astype(int), label=\"Hand Detected (1=True, 0=False)\", marker='o')\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Hand Detection\")\n",
    "plt.title(\"Hand Detection Over Time\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(output_plot_path)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Time series plot saved to {output_plot_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter DataFrame for rows where hands were detected\n",
    "hands_detected_df = df[df[\"Hand Detected\"]]\n",
    "\n",
    "# Print the filtered rows\n",
    "print(\"Rows where hands were detected:\")\n",
    "print(hands_detected_df)\n",
    "\n",
    "# Optionally, save the filtered rows to a CSV file for analysis\n",
    "output_csv_path = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\labeled_regions\\inside\\hands_detected.csv\"\n",
    "hands_detected_df.to_csv(output_csv_path, index=False)\n",
    "print(f\"Filtered rows saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for mediapipe (above) \\_\\_init__ files had to be adapted to remove audio imports and similar for the module to load\n",
    "venv with adapted modules provided in zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "output_analysis_folder = os.path.join(output_folder, \"analysis_results\")\n",
    "os.makedirs(output_analysis_folder, exist_ok=True)\n",
    "\n",
    "# State and object detection methods\n",
    "methods = [\"spinning_stationary\", \"alignment_detection\", \"foreign_object_detection\"]\n",
    "results = {method: [] for method in methods}\n",
    "\n",
    "# Define detection functions\n",
    "def detect_spinning_or_stationary(image, prev_image, threshold=30):\n",
    "    \"\"\"\n",
    "    Detect whether the reel is spinning or stationary by comparing current frame\n",
    "    with a previous frame using frame differencing.\n",
    "    \"\"\"\n",
    "    gray_current = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray_prev = cv2.cvtColor(prev_image, cv2.COLOR_BGR2GRAY)\n",
    "    diff = cv2.absdiff(gray_current, gray_prev)\n",
    "    _, thresh = cv2.threshold(diff, threshold, 255, cv2.THRESH_BINARY)\n",
    "    motion_pixels = cv2.countNonZero(thresh)\n",
    "    return \"Spinning\" if motion_pixels > 500 else \"Stationary\"\n",
    "\n",
    "def detect_cable_alignment(image):\n",
    "    \"\"\"\n",
    "    Detect cable alignment based on contours and relative positions.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) == 0:\n",
    "        return \"No cable detected\"\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    rect = cv2.boundingRect(largest_contour)\n",
    "    aspect_ratio = rect[2] / rect[3]\n",
    "    if aspect_ratio > 3:\n",
    "        return \"Misaligned\"\n",
    "    elif aspect_ratio < 0.5:\n",
    "        return \"Trapped\"\n",
    "    else:\n",
    "        return \"Aligned\"\n",
    "\n",
    "def detect_foreign_objects(image):\n",
    "    \"\"\"\n",
    "    Detect foreign objects such as hands, tools, or debris using color and contour analysis.\n",
    "    \"\"\"\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    detections = []\n",
    "    lower_skin = np.array([0, 20, 70], dtype=np.uint8)\n",
    "    upper_skin = np.array([20, 255, 255], dtype=np.uint8)\n",
    "    mask_skin = cv2.inRange(hsv, lower_skin, upper_skin)\n",
    "    if cv2.countNonZero(mask_skin) > 500:\n",
    "        detections.append(\"Hand detected\")\n",
    "    lower_red1 = np.array([0, 120, 70], dtype=np.uint8)\n",
    "    upper_red1 = np.array([10, 255, 255], dtype=np.uint8)\n",
    "    lower_red2 = np.array([170, 120, 70], dtype=np.uint8)\n",
    "    upper_red2 = np.array([180, 255, 255], dtype=np.uint8)\n",
    "    mask_red = cv2.inRange(hsv, lower_red1, upper_red1) + cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "    if cv2.countNonZero(mask_red) > 500:\n",
    "        detections.append(\"Tools detected\")\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, bright_spots = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
    "    if cv2.countNonZero(bright_spots) > 500:\n",
    "        detections.append(\"Debris above reel\")\n",
    "    return detections if detections else [\"No foreign objects detected\"]\n",
    "\n",
    "# Process images with masks sequentially\n",
    "batch_size = 50\n",
    "image_filenames = sorted([img for img in os.listdir(image_folder) if img.endswith(\".jpg\")])\n",
    "num_images = len(image_filenames)\n",
    "\n",
    "for mask_name, mask_path in tqdm(masks.items(), desc=\"Processing Masks\"):\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if mask is None:\n",
    "        raise FileNotFoundError(f\"Mask not found: {mask_path}\")\n",
    "\n",
    "    prev_image = None\n",
    "\n",
    "    for i in tqdm(range(0, num_images, batch_size), desc=f\"Processing {mask_name}\"):\n",
    "        batch_images = image_filenames[i:i + batch_size]\n",
    "        for img_name in batch_images:\n",
    "            img_path = os.path.join(image_folder, img_name)\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                print(f\"Error loading image: {img_name}\")\n",
    "                continue\n",
    "            if mask.shape[:2] != image.shape[:2]:\n",
    "                mask = cv2.resize(mask, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "            masked_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "            spinning_stationary = None\n",
    "            if prev_image is not None:\n",
    "                spinning_stationary = detect_spinning_or_stationary(masked_image, prev_image)\n",
    "            # Only apply cable alignment detection for the \"filled_mask_below\"\n",
    "            cable_state = None\n",
    "            if mask_name == \"filled_mask_below\":\n",
    "                cable_state = detect_cable_alignment(masked_image)\n",
    "            foreign_objects = detect_foreign_objects(masked_image)\n",
    "            results[\"spinning_stationary\"].append({\"image\": img_name, \"result\": spinning_stationary, \"mask\": mask_name})\n",
    "            if cable_state is not None:\n",
    "                results[\"alignment_detection\"].append({\"image\": img_name, \"result\": cable_state, \"mask\": mask_name})\n",
    "            results[\"foreign_object_detection\"].append({\"image\": img_name, \"result\": foreign_objects, \"mask\": mask_name})\n",
    "            prev_image = masked_image\n",
    "\n",
    "# Save analysis results\n",
    "for method, method_results in results.items():\n",
    "    output_json = os.path.join(output_analysis_folder, f\"{method}_analysis.json\")\n",
    "    with open(output_json, \"w\") as f:\n",
    "        json.dump(method_results, f, indent=4)\n",
    "\n",
    "print(f\"Analysis results saved to {output_analysis_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = r'D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\labeled_regions\\analysis_results\\spinning_stationary_analysis.json'\n",
    "path2 = r'D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\labeled_regions\\analysis_results\\foreign_object_detection_analysis.json'\n",
    "path3 = r'D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\labeled_regions\\analysis_results\\alignment_detection_analysis.json'\n",
    "\n",
    "with open(path1, 'r') as f:\n",
    "    results1 = json.load(f)\n",
    "with open(path2, 'r') as f:\n",
    "    results2 = json.load(f)\n",
    "with open(path3, 'r') as f:\n",
    "    results3 = json.load(f)\n",
    "\n",
    "print(\"\\nresults:\")\n",
    "pprint(results1[:1])\n",
    "print(\"\\nresults:\")\n",
    "pprint(results2[:1])\n",
    "print(\"\\nresults:\")\n",
    "pprint(results3[:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "analysis_results_folder = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\labeled_regions\\analysis_results\"\n",
    "output_visualization_folder = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\labeled_regions\\visualizations\"\n",
    "os.makedirs(output_visualization_folder, exist_ok=True)\n",
    "\n",
    "# Function to extract timestamps and features and log them as time series\n",
    "def process_and_plot_results_with_varied_formats():\n",
    "    \"\"\"\n",
    "    Processes analysis results and logs detected features as a time series graph.\n",
    "    Handles varied formats of the `result` field.\n",
    "    \"\"\"\n",
    "    time_series_data = []\n",
    "\n",
    "    # Iterate through JSON result files in the analysis results folder\n",
    "    for result_file in os.listdir(analysis_results_folder):\n",
    "        if result_file.endswith(\"_analysis.json\"):\n",
    "            result_path = os.path.join(analysis_results_folder, result_file)\n",
    "\n",
    "            # Load the analysis results\n",
    "            with open(result_path, \"r\") as f:\n",
    "                analysis_results = json.load(f)\n",
    "\n",
    "            # Extract timestamps and detected features\n",
    "            for result in analysis_results:\n",
    "                image_name = result[\"image\"]\n",
    "\n",
    "                # Extract timestamp from the image name\n",
    "                timestamp = image_name.split(\"_\")[1]  # Format: HHMMSS\n",
    "                feature_data = result.get(\"result\")\n",
    "\n",
    "                # Handle different formats of the `result` field\n",
    "                if feature_data:\n",
    "                    if isinstance(feature_data, str):  # Single feature\n",
    "                        time_series_data.append({\"Timestamp\": timestamp, \"Feature\": feature_data})\n",
    "                    elif isinstance(feature_data, list):  # Multiple features\n",
    "                        for feature in feature_data:\n",
    "                            time_series_data.append({\"Timestamp\": timestamp, \"Feature\": feature})\n",
    "\n",
    "    # Convert the time-series data into a DataFrame\n",
    "    if not time_series_data:\n",
    "        print(\"No features detected in the results.\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(time_series_data)\n",
    "\n",
    "    # Aggregate feature counts over time\n",
    "    feature_counts = df.groupby([\"Timestamp\", \"Feature\"]).size().reset_index(name=\"Count\")\n",
    "\n",
    "    # Plot each feature as a time series\n",
    "    for feature, group in feature_counts.groupby(\"Feature\"):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(group[\"Timestamp\"], group[\"Count\"], marker=\"o\", label=feature)\n",
    "        plt.title(f\"Time Series for Feature: {feature}\")\n",
    "        plt.xlabel(\"Timestamp\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        output_path = os.path.join(output_visualization_folder, f\"time_series_{feature}.png\")\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"Time series plot saved for feature '{feature}' at {output_path}\")\n",
    "\n",
    "# Execute the function\n",
    "process_and_plot_results_with_varied_formats()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paind_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
