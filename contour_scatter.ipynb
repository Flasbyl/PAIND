{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tqdm import tqdm\n",
    "import psutil\n",
    "\n",
    "#weighted distance density\n",
    "def calculate_density(centers, k, p, epsilon):\n",
    "    \"\"\"\n",
    "    Calculate density with inverse distance weighting (higher influence on larger distances).\n",
    "    p: The power of the inverse distance. Higher values of p give even more weight to larger distances.\n",
    "    epsilon: Small value to prevent division by zero for very close points.\n",
    "    \"\"\"\n",
    "    nbrs = NearestNeighbors(n_neighbors=k).fit(centers)\n",
    "    distances, _ = nbrs.kneighbors(centers)\n",
    "    \n",
    "    # Add epsilon to distances to avoid division by zero\n",
    "    distances = distances[:, 1:] + epsilon  # Ignore the point itself, use distances[:, 1:]\n",
    "    \n",
    "    # Apply inverse distance weighting (1/distance^p)\n",
    "    weights = (distances ** p)\n",
    "    weighted_density_scores = np.mean(weights, axis=1)\n",
    "\n",
    "    \n",
    "    return weighted_density_scores\n",
    "\n",
    "\n",
    "# Perform the KNN and density filtering for the specified number of iterations\n",
    "def knn(k, contour_centers, method, iterations, p, epsilon):\n",
    "    for iteration in tqdm(range(iterations), desc=f\"Iterations for {method}\"):\n",
    "        # Calculate density using KNN\n",
    "        density_scores_k = calculate_density(contour_centers, k, p, epsilon)\n",
    "\n",
    "        # Apply a logarithmic transformation to the density scores\n",
    "        #epsilon = 1e-5  # Small value to avoid log(0)\n",
    "        log_density_scores_k = np.log(density_scores_k + epsilon)\n",
    "\n",
    "        # Filter out points with a log density score above the threshold\n",
    "        filtered_indices_d = log_density_scores_k <= d\n",
    "        contour_centers = contour_centers[filtered_indices_d]\n",
    "        log_density_scores_k = log_density_scores_k[filtered_indices_d]\n",
    "        #k += 1\n",
    "        print(len(contour_centers))\n",
    "\n",
    "        # Check if there are no points left (all points filtered out)\n",
    "        if len(contour_centers) == 0:\n",
    "            print(\"No points remaining after filtering.\")\n",
    "            break\n",
    "    return (contour_centers, log_density_scores_k, filtered_indices_d)\n",
    "\n",
    "# Path to your images\n",
    "image_folder = \"D:\\\\PAIND\\\\DATA\\\\20240527_Data_Prozess_01\\\\webcam\\\\batch\"\n",
    "images = sorted([img for img in os.listdir(image_folder) if img.endswith(\".jpg\")])\n",
    "k = 20  # Single value for k\n",
    "d = 0.005  # Single density threshold\n",
    "iterations = 10  # Number of iterations to loop through the KNN and density filtering\n",
    "num_images_to_analyze = len(images)\n",
    "\n",
    "# Initialize background subtractor\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=True)\n",
    "\n",
    "# List to store the centers of contours\n",
    "contour_centers = []\n",
    "\n",
    "# Base output folder path (same path as the image folder)\n",
    "base_output_path = image_folder\n",
    "\n",
    "# Update output folders to be within the same path as the image folder\n",
    "output_folders = {\n",
    "    \"grayscale_gaussian\": os.path.join(base_output_path, \"output_grayscale_gaussian\"),\n",
    "    \"hsv_value\": os.path.join(base_output_path, \"output_hsv_value\"),\n",
    "    \"canny_edges\": os.path.join(base_output_path, \"output_canny_edges\"),\n",
    "    \"mog2_background_subtraction\": os.path.join(base_output_path, \"output_mog2_background\"),\n",
    "    \"farneback_optical_flow\": os.path.join(base_output_path, \"output_optical_flow\"),\n",
    "}\n",
    "\n",
    "# Create output folders if they don't exist\n",
    "for folder in output_folders.values():\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Analysis\n",
    "\n",
    "- Each method is applied to the images\n",
    "- contours centres are saved to json files for later analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grayscale Gaussian Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to hold the results for Grayscale Gaussian approach\n",
    "results = {\"grayscale_gaussian\": []}\n",
    "\n",
    "# Monitor RAM usage\n",
    "process = psutil.Process()\n",
    "\n",
    "# Initialize the tqdm progress bars\n",
    "progress_bar = tqdm(range(min(len(images) - 1, num_images_to_analyze)), desc=\"Processing Grayscale Gaussian\", position=0)\n",
    "ram_bar = tqdm(total=0, bar_format=\"{desc}\", position=1)  # Second tqdm line for RAM usage\n",
    "\n",
    "# Process the images for the Grayscale Gaussian approach\n",
    "for i in progress_bar:\n",
    "    img1_path = os.path.join(image_folder, images[i])\n",
    "    img2_path = os.path.join(image_folder, images[i + 1])\n",
    "    img1 = cv2.imread(img1_path)\n",
    "    img2 = cv2.imread(img2_path)\n",
    "    image_name = os.path.basename(img1_path)\n",
    "\n",
    "    # Grayscale Gaussian approach\n",
    "    gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    gray1_blurred = cv2.GaussianBlur(gray1, (21, 21), 0)\n",
    "    gray2_blurred = cv2.GaussianBlur(gray2, (21, 21), 0)\n",
    "    diff_gray = cv2.absdiff(gray1_blurred, gray2_blurred)\n",
    "    _, thresh_gray = cv2.threshold(diff_gray, 25, 255, cv2.THRESH_BINARY)\n",
    "    contours_gray, _ = cv2.findContours(thresh_gray.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour_centers = [(x + w // 2, y + h // 2) for (x, y, w, h) in [cv2.boundingRect(c) for c in contours_gray]]\n",
    "    results[\"grayscale_gaussian\"].append({\"image_name\": image_name, \"contour_centers\": contour_centers})\n",
    "\n",
    "    # Update RAM usage bar\n",
    "    ram_usage_mb = process.memory_info().rss / (1024 * 1024)  # Convert bytes to MB\n",
    "    ram_bar.set_description(f\"RAM Usage: {ram_usage_mb:.2f} MB\")\n",
    "\n",
    "# Save results for Grayscale Gaussian\n",
    "json_filename = os.path.join(output_folders[\"grayscale_gaussian\"], \"grayscale_gaussian_contour_centers.json\")\n",
    "with open(json_filename, 'w') as json_file:\n",
    "    json.dump(results[\"grayscale_gaussian\"], json_file, indent=4)\n",
    "\n",
    "print(\"Grayscale Gaussian results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ram_usage_mb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hsv Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to hold the results for HSV Value approach\n",
    "results = {\"hsv_value\": []}\n",
    "\n",
    "# Monitor RAM usage\n",
    "process = psutil.Process()\n",
    "\n",
    "# Initialize the tqdm progress bars\n",
    "progress_bar = tqdm(range(min(len(images) - 1, num_images_to_analyze)), desc=\"Processing hsv\", position=0)\n",
    "ram_bar = tqdm(total=0, bar_format=\"{desc}\", position=1)  # Second tqdm line for RAM usage\n",
    "\n",
    "# Process the images for the HSV Value approach\n",
    "for i in tqdm(range(min(len(images) - 1, num_images_to_analyze)), desc=\"Processing HSV Value\"):\n",
    "    img1_path = os.path.join(image_folder, images[i])\n",
    "    img2_path = os.path.join(image_folder, images[i + 1])\n",
    "    img1 = cv2.imread(img1_path)\n",
    "    img2 = cv2.imread(img2_path)\n",
    "    image_name = os.path.basename(img1_path)\n",
    "\n",
    "    # HSV Value channel approach\n",
    "    hsv1 = cv2.cvtColor(img1, cv2.COLOR_BGR2HSV)\n",
    "    hsv2 = cv2.cvtColor(img2, cv2.COLOR_BGR2HSV)\n",
    "    diff_hsv = cv2.absdiff(hsv1[:, :, 2], hsv2[:, :, 2])\n",
    "    _, thresh_hsv = cv2.threshold(diff_hsv, 25, 255, cv2.THRESH_BINARY)\n",
    "    contours_hsv, _ = cv2.findContours(thresh_hsv.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour_centers = [(x + w // 2, y + h // 2) for (x, y, w, h) in [cv2.boundingRect(c) for c in contours_hsv]]\n",
    "    results[\"hsv_value\"].append({\"image_name\": image_name, \"contour_centers\": contour_centers})\n",
    "\n",
    "    # Update RAM usage bar\n",
    "    ram_usage_mb = process.memory_info().rss / (1024 * 1024)  # Convert bytes to MB\n",
    "    ram_bar.set_description(f\"RAM Usage: {ram_usage_mb:.2f} MB\")\n",
    "\n",
    "# Save results for HSV Value\n",
    "json_filename = os.path.join(output_folders[\"hsv_value\"], \"hsv_value_contour_centers.json\")\n",
    "with open(json_filename, 'w') as json_file:\n",
    "    json.dump(results[\"hsv_value\"], json_file, indent=4)\n",
    "print(\"HSV Value results saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Canny Edge\n",
    "not used: too much memory usage at knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Initialize a dictionary to hold the results for Canny Edge approach\n",
    "results = {\"canny_edges\": []}\n",
    "\n",
    "# Monitor RAM usage\n",
    "process = psutil.Process()\n",
    "\n",
    "# Initialize the tqdm progress bars\n",
    "progress_bar = tqdm(range(min(len(images) - 1, num_images_to_analyze)), desc=\"Processing Canny Edges\", position=0)\n",
    "ram_bar = tqdm(total=0, bar_format=\"{desc}\", position=1)  # Second tqdm line for RAM usage\n",
    "\n",
    "# Process the images for the Canny Edge approach\n",
    "for i in tqdm(range(min(len(images) - 1, num_images_to_analyze)), desc=\"Processing Canny Edges\"):\n",
    "    img1_path = os.path.join(image_folder, images[i])\n",
    "    img2_path = os.path.join(image_folder, images[i + 1])\n",
    "    img1 = cv2.imread(img1_path)\n",
    "    img2 = cv2.imread(img2_path)\n",
    "    image_name = os.path.basename(img1_path)\n",
    "\n",
    "    # Canny edge detection approach\n",
    "    edges1 = cv2.Canny(img1, 50, 150)\n",
    "    edges2 = cv2.Canny(img2, 50, 150)\n",
    "    diff_edges = cv2.absdiff(edges1, edges2)\n",
    "    _, thresh_edges = cv2.threshold(diff_edges, 25, 255, cv2.THRESH_BINARY)\n",
    "    contours_edges, _ = cv2.findContours(thresh_edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour_centers = [(x + w // 2, y + h // 2) for (x, y, w, h) in [cv2.boundingRect(c) for c in contours_edges]]\n",
    "    results[\"canny_edges\"].append({\"image_name\": image_name, \"contour_centers\": contour_centers})\n",
    "\n",
    "    # Update RAM usage bar\n",
    "    ram_usage_mb = process.memory_info().rss / (1024 * 1024)  # Convert bytes to MB\n",
    "    ram_bar.set_description(f\"RAM Usage: {ram_usage_mb:.2f} MB\")\n",
    "\n",
    "# Save results for Canny Edge\n",
    "json_filename = os.path.join(output_folders[\"canny_edges\"], \"canny_edges_contour_centers.json\")\n",
    "with open(json_filename, 'w') as json_file:\n",
    "    json.dump(results[\"canny_edges\"], json_file, indent=4)\n",
    "print(\"Canny Edges results saved.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mog2 Background Subtraction\n",
    "not used: too much memory usage at knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Initialize a dictionary to hold the results for MOG2 background subtraction approach\n",
    "results = {\"mog2_background_subtraction\": []}\n",
    "\n",
    "# Monitor RAM usage\n",
    "process = psutil.Process()\n",
    "\n",
    "# Initialize the tqdm progress bars\n",
    "progress_bar = tqdm(range(min(len(images) - 1, num_images_to_analyze)), desc=\"Processing Mog2\", position=0)\n",
    "ram_bar = tqdm(total=0, bar_format=\"{desc}\", position=1)  # Second tqdm line for RAM usage\n",
    "\n",
    "# Process the images for the MOG2 background subtraction approach\n",
    "for i in tqdm(range(min(len(images) - 1, num_images_to_analyze)), desc=\"Processing MOG2 Background Subtraction\"):\n",
    "    img1_path = os.path.join(image_folder, images[i])\n",
    "    img2_path = os.path.join(image_folder, images[i + 1])\n",
    "    img1 = cv2.imread(img1_path)\n",
    "    img2 = cv2.imread(img2_path)\n",
    "    image_name = os.path.basename(img1_path)\n",
    "\n",
    "    # MOG2 background subtraction approach\n",
    "    fgmask1 = fgbg.apply(img1)\n",
    "    fgmask2 = fgbg.apply(img2)\n",
    "    diff_mog2 = cv2.absdiff(fgmask1, fgmask2)\n",
    "    _, thresh_mog2 = cv2.threshold(diff_mog2, 25, 255, cv2.THRESH_BINARY)\n",
    "    contours_mog2, _ = cv2.findContours(thresh_mog2.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour_centers = [(x + w // 2, y + h // 2) for (x, y, w, h) in [cv2.boundingRect(c) for c in contours_mog2]]\n",
    "    results[\"mog2_background_subtraction\"].append({\"image_name\": image_name, \"contour_centers\": contour_centers})\n",
    "\n",
    "    # Update RAM usage bar\n",
    "    ram_usage_mb = process.memory_info().rss / (1024 * 1024)  # Convert bytes to MB\n",
    "    ram_bar.set_description(f\"RAM Usage: {ram_usage_mb:.2f} MB\")\n",
    "\n",
    "# Save results for MOG2 background subtraction\n",
    "json_filename = os.path.join(output_folders[\"mog2_background_subtraction\"], \"mog2_background_subtraction_contour_centers.json\")\n",
    "with open(json_filename, 'w') as json_file:\n",
    "    json.dump(results[\"mog2_background_subtraction\"], json_file, indent=4)\n",
    "print(\"MOG2 Background Subtraction results saved.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Farneback Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to hold the results for Farneback Optical Flow approach\n",
    "results = {\"farneback_optical_flow\": []}\n",
    "\n",
    "# Monitor RAM usage\n",
    "process = psutil.Process()\n",
    "\n",
    "# Initialize the tqdm progress bars\n",
    "progress_bar = tqdm(range(min(len(images) - 1, num_images_to_analyze)), desc=\"Processing Farneback\", position=0)\n",
    "ram_bar = tqdm(total=0, bar_format=\"{desc}\", position=1)  # Second tqdm line for RAM usage\n",
    "\n",
    "# Process the images for the Farneback Optical Flow approach\n",
    "for i in tqdm(range(min(len(images) - 1, num_images_to_analyze)), desc=\"Processing Farneback Optical Flow\"):\n",
    "    img1_path = os.path.join(image_folder, images[i])\n",
    "    img2_path = os.path.join(image_folder, images[i + 1])\n",
    "    img1 = cv2.imread(img1_path)\n",
    "    img2 = cv2.imread(img2_path)\n",
    "    image_name = os.path.basename(img1_path)\n",
    "\n",
    "    # Convert images to grayscale\n",
    "    gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Farneback optical flow approach\n",
    "    flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    diff_optical_flow = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    _, thresh_optical_flow = cv2.threshold(diff_optical_flow, 25, 255, cv2.THRESH_BINARY)\n",
    "    contours_optical_flow, _ = cv2.findContours(thresh_optical_flow.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour_centers = [(x + w // 2, y + h // 2) for (x, y, w, h) in [cv2.boundingRect(c) for c in contours_optical_flow]]\n",
    "    results[\"farneback_optical_flow\"].append({\"image_name\": image_name, \"contour_centers\": contour_centers})\n",
    "\n",
    "    # Log RAM usage dynamically\n",
    "    ram_usage_mb = process.memory_info().rss / (1024 * 1024)  # Convert bytes to MB\n",
    "    progress_bar.set_description(f\"Processing {image_name} | RAM Usage: {ram_usage_mb:.2f} MB\")\n",
    "\n",
    "# Save results for Farneback Optical Flow\n",
    "json_filename = os.path.join(output_folders[\"farneback_optical_flow\"], \"farneback_optical_flow_contour_centers.json\")\n",
    "with open(json_filename, 'w') as json_file:\n",
    "    json.dump(results[\"farneback_optical_flow\"], json_file, indent=4)\n",
    "print(\"Farneback Optical Flow results saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check number of contours for each method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the number of contour centers in each method's JSON file\n",
    "for method, folder in output_folders.items():\n",
    "    json_filename = os.path.join(folder, f\"{method}_contour_centers.json\")\n",
    "    \n",
    "    # Load the contour centers from the JSON file\n",
    "    with open(json_filename, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    # Count the total number of contour centers across all images\n",
    "    total_contour_centers = sum(len(item[\"contour_centers\"]) for item in data)\n",
    "    \n",
    "    # Output the results\n",
    "    print(f\"MethoE: {method}, Number of Contour Centers: {total_contour_centers}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction of contours\n",
    "\n",
    "- load json \n",
    "- reduce contours using knn\n",
    "- plot reduced centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Values for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 20  # Single value for k\n",
    "d = 0.05  # Single density threshold\n",
    "p = 20\n",
    "epsilon = 1e-7\n",
    "iterations = 5  # Number of iterations to loop through the KNN and density filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method, folder in tqdm(output_folders.items(), desc=\"Processing Methods\"):\n",
    "    json_filename = os.path.join(folder, f\"{method}_contour_centers.json\")\n",
    "    print(json_filename)\n",
    "    print(method)\n",
    "    print(folder)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grayscale Gaussian\n",
    "ttr = 11m 41.4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"grayscale_gaussian\"\n",
    "json_filename = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\batch\\output_grayscale_gaussian\\grayscale_gaussian_contour_centers.json\"\n",
    "folder = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\batch\\output_grayscale_gaussian\"\n",
    "\n",
    "\n",
    "\n",
    "# Load the contour centers from the JSON file\n",
    "with open(json_filename, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Extract the contour centers for all images\n",
    "contour_centers = []\n",
    "for item in tqdm(data, desc=f\"Extracting Contours for {method}\"):\n",
    "    contour_centers.extend(item[\"contour_centers\"])\n",
    "\n",
    "contour_centers = np.array(contour_centers)\n",
    "\n",
    "contour_centers_grayscale, log_density_scores_k_grayscale, filtered_indices_d = knn(k, contour_centers, method, iterations, p, epsilon)\n",
    "\n",
    "# Normalize the final filtered log density scores for color mapping\n",
    "norm_log_density_scores_final_grayscale = (log_density_scores_k_grayscale - log_density_scores_k_grayscale.min()) / (log_density_scores_k_grayscale.max() - log_density_scores_k_grayscale.min())\n",
    "\n",
    "# Create a color map based on log density (red for high density, blue for low density)\n",
    "colors_final_grayscale = plt.cm.jet(norm_log_density_scores_final_grayscale)\n",
    "\n",
    "# Plot the final result\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "scatter_final = ax.scatter(contour_centers_grayscale[:, 0], contour_centers_grayscale[:, 1], color=colors_final_grayscale, s=10)\n",
    "ax.set_title(f\"{method} - Contour Centers with Log Density after {iterations} Iterations\\n(k={k-iterations}-{k}, d={d})\", fontsize=10)\n",
    "ax.set_xlabel(\"X Coordinate\")\n",
    "ax.set_ylabel(\"Y Coordinate\")\n",
    "ax.invert_yaxis()\n",
    "plt.colorbar(scatter_final, ax=ax, label='Log Density (neighbor distance)')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot to the same location as the JSON file\n",
    "plot_filename = os.path.join(folder, f\"{method}_contour_centers_plot.png\")\n",
    "plt.savefig(plot_filename)\n",
    "plt.close(fig)\n",
    "\n",
    "print(f\"Plot saved to {plot_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hsv\n",
    "ttr = 395min 42.9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"hsv_value\"\n",
    "json_filename = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\batch\\output_hsv_value\\hsv_value_contour_centers.json\"\n",
    "folder = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\batch\\output_hsv_value\"\n",
    "\n",
    "\n",
    "# Load the contour centers from the JSON file\n",
    "with open(json_filename, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Extract the contour centers for all images\n",
    "contour_centers = []\n",
    "for item in tqdm(data, desc=f\"Extracting Contours for {method}\"):\n",
    "    contour_centers.extend(item[\"contour_centers\"])\n",
    "\n",
    "contour_centers = np.array(contour_centers)\n",
    "\n",
    "\n",
    "contour_centers_hsv, log_density_scores_k_hsv, filtered_indices_d = knn(k, contour_centers, method, iterations, p, epsilon)\n",
    "\n",
    "\n",
    "# Normalize the final filtered log density scores for color mapping\n",
    "norm_log_density_scores_final_hsv = (log_density_scores_k_hsv - log_density_scores_k_hsv.min()) / (log_density_scores_k_hsv.max() - log_density_scores_k_hsv.min())\n",
    "\n",
    "# Create a color map based on log density (red for high density, blue for low density)\n",
    "colors_final_hsv = plt.cm.jet(norm_log_density_scores_final_hsv)\n",
    "\n",
    "# Plot the final result\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "scatter_final = ax.scatter(contour_centers_hsv[:, 0], contour_centers_hsv[:, 1], color=colors_final_hsv, s=10)\n",
    "ax.set_title(f\"{method} - Contour Centers with Log Density after {iterations} Iterations\\n(k={k-iterations}-{k}, d={d})\", fontsize=10)\n",
    "ax.set_xlabel(\"X Coordinate\")\n",
    "ax.set_ylabel(\"Y Coordinate\")\n",
    "ax.invert_yaxis()\n",
    "plt.colorbar(scatter_final, ax=ax, label='Log Density (neighbor distance)')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot to the same location as the JSON file\n",
    "plot_filename = os.path.join(folder, f\"{method}_contour_centers_plot.png\")\n",
    "plt.savefig(plot_filename)\n",
    "plt.close(fig)\n",
    "\n",
    "print(f\"Plot saved to {plot_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Canny Edge\n",
    "not enough memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"method = \"canny_edges\"\n",
    "json_filename = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\batch\\output_canny_edges\\canny_edges_contour_centers.json\"\n",
    "folder = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\batch\\output_canny_edges\"\n",
    "\n",
    "\n",
    "\n",
    "# Load the contour centers from the JSON file\n",
    "with open(json_filename, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Extract the contour centers for all images\n",
    "contour_centers = []\n",
    "for item in tqdm(data, desc=f\"Extracting Contours for {method}\"):\n",
    "    contour_centers.extend(item[\"contour_centers\"])\n",
    "\n",
    "contour_centers = np.array(contour_centers)\n",
    "\n",
    "# Perform the KNN and density filtering for the specified number of iterations\n",
    "for iteration in tqdm(range(iterations), desc=f\"Iterations for {method}\"):\n",
    "    # Calculate density using KNN\n",
    "    density_scores_k = calculate_density(contour_centers, k)\n",
    "\n",
    "    # Apply a logarithmic transformation to the density scores\n",
    "    epsilon = 1e-5  # Small value to avoid log(0)\n",
    "    log_density_scores_k = np.log(density_scores_k + epsilon)\n",
    "\n",
    "    # Filter out points with a log density score above the threshold\n",
    "    filtered_indices_d = log_density_scores_k <= d\n",
    "    contour_centers = contour_centers[filtered_indices_d]\n",
    "    log_density_scores_k = log_density_scores_k[filtered_indices_d]\n",
    "    #k += 1\n",
    "    print(len(contour_centers))\n",
    "\n",
    "    # Check if there are no points left (all points filtered out)\n",
    "    if len(contour_centers) == 0:\n",
    "        print(\"No points remaining after filtering.\")\n",
    "        break\n",
    "\n",
    "# Normalize the final filtered log density scores for color mapping\n",
    "norm_log_density_scores_final = (log_density_scores_k - log_density_scores_k.min()) / (log_density_scores_k.max() - log_density_scores_k.min())\n",
    "\n",
    "# Create a color map based on log density (red for high density, blue for low density)\n",
    "colors_final = plt.cm.jet(norm_log_density_scores_final)\n",
    "\n",
    "# Plot the final result\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "scatter_final = ax.scatter(contour_centers[:, 0], contour_centers[:, 1], color=colors_final, s=10)\n",
    "ax.set_title(f\"{method} - Contour Centers with Log Density after {iterations} Iterations\\n(k={k-iterations}-{k}, d={d})\", fontsize=10)\n",
    "ax.set_xlabel(\"X Coordinate\")\n",
    "ax.set_ylabel(\"Y Coordinate\")\n",
    "ax.invert_yaxis()\n",
    "plt.colorbar(scatter_final, ax=ax, label='Log Density (neighbor distance)')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot to the same location as the JSON file\n",
    "plot_filename = os.path.join(folder, f\"{method}_contour_centers_plot.png\")\n",
    "plt.savefig(plot_filename)\n",
    "plt.close(fig)\n",
    "\n",
    "print(f\"Plot saved to {plot_filename}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mog2\n",
    "not enough memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"method = \"mog2_background_subtraction\"\n",
    "json_filename = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\batch\\output_mog2_background\\mog2_background_subtraction_contour_centers.json\"\n",
    "folder = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\batch\\output_mog2_background\"\n",
    "\n",
    "\n",
    "\n",
    "# Load the contour centers from the JSON file\n",
    "with open(json_filename, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Extract the contour centers for all images\n",
    "contour_centers = []\n",
    "for item in tqdm(data, desc=f\"Extracting Contours for {method}\"):\n",
    "    contour_centers.extend(item[\"contour_centers\"])\n",
    "\n",
    "contour_centers = np.array(contour_centers)\n",
    "\n",
    "# Perform the KNN and density filtering for the specified number of iterations\n",
    "for iteration in tqdm(range(iterations), desc=f\"Iterations for {method}\"):\n",
    "    # Calculate density using KNN\n",
    "    density_scores_k = calculate_density(contour_centers, k)\n",
    "\n",
    "    # Apply a logarithmic transformation to the density scores\n",
    "    epsilon = 1e-5  # Small value to avoid log(0)\n",
    "    log_density_scores_k = np.log(density_scores_k + epsilon)\n",
    "\n",
    "    # Filter out points with a log density score above the threshold\n",
    "    filtered_indices_d = log_density_scores_k <= d\n",
    "    contour_centers = contour_centers[filtered_indices_d]\n",
    "    log_density_scores_k = log_density_scores_k[filtered_indices_d]\n",
    "    #k += 1\n",
    "    print(len(contour_centers))\n",
    "\n",
    "    # Check if there are no points left (all points filtered out)\n",
    "    if len(contour_centers) == 0:\n",
    "        print(\"No points remaining after filtering.\")\n",
    "        break\n",
    "\n",
    "# Normalize the final filtered log density scores for color mapping\n",
    "norm_log_density_scores_final = (log_density_scores_k - log_density_scores_k.min()) / (log_density_scores_k.max() - log_density_scores_k.min())\n",
    "\n",
    "# Create a color map based on log density (red for high density, blue for low density)\n",
    "colors_final = plt.cm.jet(norm_log_density_scores_final)\n",
    "\n",
    "# Plot the final result\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "scatter_final = ax.scatter(contour_centers[:, 0], contour_centers[:, 1], color=colors_final, s=10)\n",
    "ax.set_title(f\"{method} - Contour Centers with Log Density after {iterations} Iterations\\n(k={k-iterations}-{k}, d={d})\", fontsize=10)\n",
    "ax.set_xlabel(\"X Coordinate\")\n",
    "ax.set_ylabel(\"Y Coordinate\")\n",
    "ax.invert_yaxis()\n",
    "plt.colorbar(scatter_final, ax=ax, label='Log Density (neighbor distance)')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot to the same location as the JSON file\n",
    "plot_filename = os.path.join(folder, f\"{method}_contour_centers_plot.png\")\n",
    "plt.savefig(plot_filename)\n",
    "plt.close(fig)\n",
    "\n",
    "print(f\"Plot saved to {plot_filename}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Farneback\n",
    "ttr = 150min 48s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"farneback_optical_flow\"\n",
    "json_filename = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\batch\\output_optical_flow\\farneback_optical_flow_contour_centers.json\"\n",
    "folder = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\batch\\output_optical_flow\"\n",
    "\n",
    "\n",
    "\n",
    "# Load the contour centers from the JSON file\n",
    "with open(json_filename, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Extract the contour centers for all images\n",
    "contour_centers = []\n",
    "for item in tqdm(data, desc=f\"Extracting Contours for {method}\"):\n",
    "    contour_centers.extend(item[\"contour_centers\"])\n",
    "\n",
    "contour_centers = np.array(contour_centers)\n",
    "\n",
    "\n",
    "contour_centers_farneback, log_density_scores_k_farneback, filtered_indices_d = knn(k, contour_centers, method, iterations, p, epsilon)\n",
    "\n",
    "# Normalize the final filtered log density scores for color mapping\n",
    "norm_log_density_scores_final_farneback = (log_density_scores_k_farneback - log_density_scores_k_farneback.min()) / (log_density_scores_k_farneback.max() - log_density_scores_k_farneback.min())\n",
    "\n",
    "# Create a color map based on log density (red for high density, blue for low density)\n",
    "colors_final_farneback = plt.cm.jet(norm_log_density_scores_final_farneback)\n",
    "\n",
    "# Plot the final result\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "scatter_final = ax.scatter(contour_centers_farneback[:, 0], contour_centers_farneback[:, 1], color=colors_final_farneback, s=10)\n",
    "ax.set_title(f\"{method} - Contour Centers with Log Density after {iterations} Iterations\\n(k={k-iterations}-{k}, d={d})\", fontsize=10)\n",
    "ax.set_xlabel(\"X Coordinate\")\n",
    "ax.set_ylabel(\"Y Coordinate\")\n",
    "ax.invert_yaxis()\n",
    "plt.colorbar(scatter_final, ax=ax, label='Log Density (neighbor distance)')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot to the same location as the JSON file\n",
    "plot_filename = os.path.join(folder, f\"{method}_contour_centers_plot.png\")\n",
    "plt.savefig(plot_filename)\n",
    "plt.close(fig)\n",
    "\n",
    "print(f\"Plot saved to {plot_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save KNNs to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base path to the output folders\n",
    "base_output_path = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\batch\"\n",
    "\n",
    "# Dynamically determine the folder paths and methods\n",
    "output_folders = {\n",
    "    \"grayscale_gaussian\": os.path.join(base_output_path, \"output_grayscale_gaussian\"),\n",
    "    \"hsv_value\": os.path.join(base_output_path, \"output_hsv_value\"),\n",
    "    \"canny_edges\": os.path.join(base_output_path, \"output_canny_edges\"),\n",
    "    \"mog2_background_subtraction\": os.path.join(base_output_path, \"output_mog2_background\"),\n",
    "    \"farneback_optical_flow\": os.path.join(base_output_path, \"output_optical_flow\"),\n",
    "}\n",
    "\n",
    "# Dictionary to map methods to their corresponding contour centers\n",
    "knns = {\n",
    "    \"grayscale_gaussian\": contour_centers_grayscale,\n",
    "    \"farneback_optical_flow\": contour_centers_farneback,\n",
    "    \"hsv_value\": contour_centers_hsv,\n",
    "    # Add more methods and their corresponding data if available\n",
    "}\n",
    "\n",
    "# Iterate through methods and save results\n",
    "for method, contour_centers in tqdm(knns.items(), desc=\"Saving KNN Results\"):\n",
    "    # Dynamically locate the folder for the method\n",
    "    folder = output_folders.get(method)\n",
    "    if folder is None:\n",
    "        print(f\"No folder found for method: {method}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Generate the JSON filename dynamically based on the method\n",
    "    json_filename = os.path.join(folder, f\"{method}_knn_contour_centers.json\")\n",
    "\n",
    "    # Prepare the data to save\n",
    "    results = [{\"contour_centers\": contour.tolist()} for contour in contour_centers]\n",
    "\n",
    "    # Ensure the folder exists\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Save the results as a JSON file\n",
    "    with open(json_filename, 'w') as json_file:\n",
    "        json.dump(results, json_file, indent=4)\n",
    "\n",
    "    print(f\"KNN results for {method} saved to {json_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"grayscale_gaussian\"\n",
    "json_filename = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\batch\\output_grayscale_gaussian\\grayscale_gaussian_knn_contour_centers.json\"\n",
    "folder = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\batch\\output_grayscale_gaussian\"\n",
    "\n",
    "# Load the contour centers from the JSON file\n",
    "with open(json_filename, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "contour_centers = []\n",
    "for item in tqdm(data, desc=f\"Extracting Contours for {method}\"):\n",
    "    contour_centers.extend(item[\"contour_centers\"])\n",
    "\n",
    "contour_centers = np.array(contour_centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define paths and parameters\n",
    "example_img_path = \"D:\\\\PAIND\\\\DATA\\\\20240527_Data_Prozess_01\\\\webcam\\\\batch\\\\20240527_140517546_imgwebcam.jpg\"\n",
    "contour_centers = np.array([[x, y] for x, y in zip(range(50, 500, 10), range(50, 500, 10))])  # Example data; replace with actual contour centers\n",
    "\n",
    "# Load an example image to get the dimensions\n",
    "example_img = cv2.imread(example_img_path)\n",
    "if example_img is None:\n",
    "    raise FileNotFoundError(f\"Image at {example_img_path} could not be loaded.\")\n",
    "\n",
    "img_height, img_width = example_img.shape[:2]\n",
    "y_threshold = 0  # Adjust this value based on your specific data and reel position\n",
    "\n",
    "# Filter out contour centers above the Y-coordinate threshold (optional)\n",
    "# Uncomment and adjust the line below if needed\n",
    "# filtered_contour_centers = contour_centers[contour_centers[:, 1] > y_threshold]\n",
    "filtered_contour_centers = contour_centers  # Use unfiltered centers if no filter is applied\n",
    "\n",
    "# Create a convex hull of the filtered points\n",
    "points = np.array(filtered_contour_centers, dtype=np.int32)\n",
    "hull = cv2.convexHull(points)\n",
    "\n",
    "# Draw the convex hull on a blank mask\n",
    "mask = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "cv2.drawContours(mask, [hull], -1, 255, -1)  # Fill the convex hull with white (255)\n",
    "\n",
    "# Save the mask\n",
    "output_mask_path = \"filtered_convex_hull_mask.png\"\n",
    "cv2.imwrite(output_mask_path, mask)\n",
    "print(f\"Mask saved to {output_mask_path}\")\n",
    "\n",
    "# Display the mask\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(mask, cmap='gray')\n",
    "plt.title(\"Filtered Convex Hull Mask\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the mask on the left and the contour centers on the right\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 8))\n",
    "\n",
    "# Left plot: Filtered convex hull mask with axis labels and matching extent\n",
    "axs[0].imshow(mask, cmap='gray', extent=[0, img_width, img_height, 0])  # Set extent to match the image dimensions\n",
    "axs[0].set_title(\"Filtered Convex Hull Mask\")\n",
    "axs[0].set_xlabel(\"X Coordinate (Width)\")\n",
    "axs[0].set_ylabel(\"Y Coordinate (Height)\")\n",
    "axs[0].axis('on')  # Ensure the axes are visible\n",
    "\n",
    "# Right plot: Contour centers with axis labels\n",
    "axs[1].scatter(filtered_contour_centers[:, 0], filtered_contour_centers[:, 1], c='red', s=10)\n",
    "axs[1].invert_yaxis()  # Invert Y-axis to match image coordinates\n",
    "axs[1].set_title(\"Filtered Contour Centers\")\n",
    "axs[1].set_xlabel(\"X Coordinate (Width)\")\n",
    "axs[1].set_ylabel(\"Y Coordinate (Height)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### troubleshooting contour centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "# Define the file paths\n",
    "flat_original_file = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\batch\\output_grayscale_gaussian\\flat_original_contour_centers.json\"\n",
    "flat_reduced_file = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\batch\\output_grayscale_gaussian\\flat_knn_contour_centers.json\"\n",
    "original_centers_file = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\batch\\output_grayscale_gaussian\\grayscale_gaussian_contour_centers.json\"\n",
    "knn_centers_file = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\batch\\output_grayscale_gaussian\\grayscale_gaussian_knn_contour_centers.json\"\n",
    "\n",
    "# Load the original centers\n",
    "with open(flat_original_file, 'r') as f:\n",
    "    original_centers = json.load(f)\n",
    "\n",
    "# Load the KNN centers\n",
    "with open(flat_reduced_file, 'r') as f:\n",
    "    knn_centers = json.load(f)\n",
    "\n",
    "# Print the first couple of lines for comparison\n",
    "print(\"Original Contour Centers:\")\n",
    "pprint(original_centers[:10])\n",
    "\n",
    "print(\"\\nKNN Reduced Contour Centers:\")\n",
    "pprint(knn_centers[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adjust json storage format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Paths to the JSON files\n",
    "original_json_path = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\batch\\output_grayscale_gaussian\\grayscale_gaussian_contour_centers.json\"\n",
    "reduced_json_path = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\batch\\output_grayscale_gaussian\\grayscale_gaussian_knn_contour_centers.json\"\n",
    "\n",
    "# Load the original contour centers\n",
    "with open(original_json_path, 'r') as f:\n",
    "    original_data = json.load(f)\n",
    "\n",
    "# Load the KNN-reduced contour centers\n",
    "with open(reduced_json_path, 'r') as f:\n",
    "    reduced_data = json.load(f)\n",
    "\n",
    "# Flatten the original contour centers\n",
    "flat_original_centers = []\n",
    "for entry in original_data:\n",
    "    flat_original_centers.extend(entry[\"contour_centers\"])\n",
    "\n",
    "flat_original_centers = np.array(flat_original_centers, dtype=np.int32)\n",
    "\n",
    "# Convert the reduced contour centers into a flat structure if not already\n",
    "flat_reduced_centers = np.array(\n",
    "    [entry[\"contour_centers\"] for entry in reduced_data], dtype=np.int32\n",
    ")\n",
    "\n",
    "# Save the flattened structures back to JSON\n",
    "flat_original_file = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\batch\\output_grayscale_gaussian\\flat_original_contour_centers.json\"\n",
    "flat_reduced_file = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\batch\\output_grayscale_gaussian\\flat_knn_contour_centers.json\"\n",
    "\n",
    "with open(flat_original_file, 'w') as f:\n",
    "    json.dump(flat_original_centers.tolist(), f, indent=4)\n",
    "\n",
    "with open(flat_reduced_file, 'w') as f:\n",
    "    json.dump(flat_reduced_centers.tolist(), f, indent=4)\n",
    "\n",
    "print(f\"Flattened original centers saved to {flat_original_file}\")\n",
    "print(f\"Flattened reduced centers saved to {flat_reduced_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### switch contour centers here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Parameters and file paths\n",
    "method = \"grayscale_gaussian\"\n",
    "json_filename = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\batch\\output_grayscale_gaussian\\grayscale_gaussian_knn_contour_centers.json\"\n",
    "folder = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\batch\\output_grayscale_gaussian\"\n",
    "example_img_path = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\batch\\20240527_140517546_imgwebcam.jpg\"\n",
    "\n",
    "# Load the contour centers from the JSON file\n",
    "with open(flat_reduced_file, 'r') as json_file:\n",
    "    contour_centers = json.load(json_file)\n",
    "\n",
    "# Convert the flat list into a NumPy array\n",
    "contour_centers = np.array(contour_centers, dtype=np.int32)\n",
    "\n",
    "# Load an example image to get the dimensions\n",
    "example_img = cv2.imread(example_img_path)\n",
    "img_height, img_width = example_img.shape[:2]\n",
    "\n",
    "# Set a Y-coordinate threshold to filter points\n",
    "y_threshold = 0  # Adjust this value based on your specific data and reel position\n",
    "\n",
    "# Filter out contour centers above the Y-coordinate threshold\n",
    "filtered_contour_centers = contour_centers[contour_centers[:, 1] > y_threshold]\n",
    "\n",
    "# Create a blank mask\n",
    "mask = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "\n",
    "# Plot the filtered points onto the mask\n",
    "for point in filtered_contour_centers:\n",
    "    x, y = int(point[0]), int(point[1])\n",
    "    mask[y, x] = 255  # Set points to white on the mask\n",
    "\n",
    "# Dilation to connect nearby points\n",
    "kernel_size = 5  # Adjust kernel size as needed\n",
    "kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "mask_dilated = cv2.dilate(mask, kernel, iterations=1)\n",
    "\n",
    "# Find contours in the dilated mask\n",
    "contours, _ = cv2.findContours(mask_dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Approximate each contour with more points to increase corners\n",
    "approximated_contours = []\n",
    "for contour in contours:\n",
    "    if cv2.contourArea(contour) > 100:  # Filter small contours based on area\n",
    "        epsilon = 0.005 * cv2.arcLength(contour, True)  # Adjust epsilon for more/fewer corners\n",
    "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        approximated_contours.append(approx)\n",
    "\n",
    "# Draw all approximated contours on a new mask\n",
    "mask_approx = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "cv2.drawContours(mask_approx, approximated_contours, -1, 255, -1)  # Fill contours with white\n",
    "\n",
    "# Plot the original dilated mask and the approximated contour mask side by side\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 8))\n",
    "\n",
    "# Left plot: Mask with original dilated points\n",
    "axs[0].imshow(mask_dilated, cmap='gray', extent=[0, img_width, img_height, 0])\n",
    "axs[0].set_title(\"Mask with Original Dilated Contour\")\n",
    "axs[0].set_xlabel(\"X Coordinate (Width)\")\n",
    "axs[0].set_ylabel(\"Y Coordinate (Height)\")\n",
    "\n",
    "# Right plot: Mask with approximated contours\n",
    "axs[1].imshow(mask_approx, cmap='gray', extent=[0, img_width, img_height, 0])\n",
    "axs[1].set_title(\"Mask with Approximated Contour\")\n",
    "axs[1].set_xlabel(\"X Coordinate (Width)\")\n",
    "axs[1].set_ylabel(\"Y Coordinate (Height)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the same example image\n",
    "example_img = cv2.imread(example_img_path)\n",
    "\n",
    "# Ensure the mask is in the same shape and type as the image (e.g., 3 channels)\n",
    "mask_3channel = cv2.merge([mask_approx] * 3)\n",
    "\n",
    "# Apply the mask to the example image\n",
    "masked_image = cv2.bitwise_and(example_img, mask_3channel)\n",
    "\n",
    "# Display the masked image\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cv2.cvtColor(masked_image, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for correct color display\n",
    "plt.title(\"Image with Mask Applied\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Parameters and file paths\n",
    "img_height, img_width = 720, 1280  # Set based on your image size if known\n",
    "example_img_path = \"D:\\\\PAIND\\\\DATA\\\\20240527_Data_Prozess_01\\\\webcam\\\\batch\\\\20240527_140517546_imgwebcam.jpg\"\n",
    "\n",
    "# Create a blank mask\n",
    "mask_outside = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "\n",
    "# Define points for the left triangular mask, extending vertically upward from the current points\n",
    "triangle_left_points = np.array([[0, 0], [200, 0], [200, 300], [0, 700]], dtype=np.int32)\n",
    "\n",
    "# Define points for the right triangular mask (mirrored configuration), extending vertically upward\n",
    "triangle_right_points = np.array([[img_width, 0], [img_width - 200, 0], [img_width - 200, 300], [img_width, 700]], dtype=np.int32)\n",
    "\n",
    "# Draw the left triangle on the mask\n",
    "cv2.fillPoly(mask_outside, [triangle_left_points], 255)  # Fill with white (255) for visibility\n",
    "\n",
    "# Draw the right triangle on the mask\n",
    "cv2.fillPoly(mask_outside, [triangle_right_points], 255)  # Fill with white (255) for visibility\n",
    "\n",
    "# Load the example image and apply the mask overlay\n",
    "example_img = cv2.imread(example_img_path)\n",
    "overlayed_img = example_img.copy()\n",
    "overlayed_img[mask_outside == 255] = [0, 0, 255]  # Color the masked region in red for visualization\n",
    "\n",
    "# Plot the standalone mask and the image with the mask overlay\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 8))\n",
    "\n",
    "# Left plot: Mask with triangular regions\n",
    "axs[0].imshow(mask_outside, cmap='gray', extent=[0, img_width, img_height, 0])\n",
    "axs[0].set_title(\"Mask with Left and Right Vertical Triangular Regions\")\n",
    "axs[0].set_xlabel(\"X Coordinate (Width)\")\n",
    "axs[0].set_ylabel(\"Y Coordinate (Height)\")\n",
    "\n",
    "# Right plot: Image with mask overlay\n",
    "axs[1].imshow(cv2.cvtColor(overlayed_img, cv2.COLOR_BGR2RGB))\n",
    "axs[1].set_title(\"Example Image with Mask Overlay\")\n",
    "axs[1].set_xlabel(\"X Coordinate (Width)\")\n",
    "axs[1].set_ylabel(\"Y Coordinate (Height)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the deduction\n",
    "deducted_mask_outside = cv2.bitwise_and(mask_outside, cv2.bitwise_not(mask_approx))\n",
    "\n",
    "# Plot the masks side by side\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 8))\n",
    "\n",
    "# Original `another_mask`\n",
    "axs[0].imshow(mask_outside, cmap='gray', extent=[0, img_width, img_height, 0])\n",
    "axs[0].set_title(\"Original Mask\")\n",
    "axs[0].set_xlabel(\"X Coordinate (Width)\")\n",
    "axs[0].set_ylabel(\"Y Coordinate (Height)\")\n",
    "\n",
    "# `mask_approx`\n",
    "axs[1].imshow(mask_approx, cmap='gray', extent=[0, img_width, img_height, 0])\n",
    "axs[1].set_title(\"Mask to Deduct (mask_approx)\")\n",
    "axs[1].set_xlabel(\"X Coordinate (Width)\")\n",
    "axs[1].set_ylabel(\"Y Coordinate (Height)\")\n",
    "\n",
    "# Resulting `deducted_mask`\n",
    "axs[2].imshow(deducted_mask_outside, cmap='gray', extent=[0, img_width, img_height, 0])\n",
    "axs[2].set_title(\"Resulting Mask After Deduction\")\n",
    "axs[2].set_xlabel(\"X Coordinate (Width)\")\n",
    "axs[2].set_ylabel(\"Y Coordinate (Height)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the resulting mask for later use or inspection\n",
    "output_path = os.path.join(folder, \"deducted_mask_outside.png\")\n",
    "cv2.imwrite(output_path, deducted_mask_outside)\n",
    "print(f\"Deducted mask saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the example image\n",
    "example_img = cv2.imread(example_img_path)\n",
    "\n",
    "# Assume `filtered_contour_centers` contains the reduced contour points for the reel\n",
    "points = np.array(filtered_contour_centers, dtype=np.int32)\n",
    "\n",
    "# Calculate the center X-coordinate of the image\n",
    "center_x = img_width // 2\n",
    "\n",
    "# Find the innermost points on the left and right closest to the center\n",
    "left_point = min(points[points[:, 0] < center_x], key=lambda p: abs(p[0] - center_x))\n",
    "right_point = min(points[points[:, 0] > center_x], key=lambda p: abs(p[0] - center_x))\n",
    "\n",
    "# Create a blank mask for the above region\n",
    "mask_above = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "\n",
    "# Define the region above the line between `left_point` and `right_point`\n",
    "polygon_above = np.array([[0, 0], [img_width, 0], right_point, left_point], dtype=np.int32)\n",
    "\n",
    "# Draw the polygon on the mask\n",
    "cv2.fillPoly(mask_above, [polygon_above], 255)\n",
    "\n",
    "# Apply the mask to the example image\n",
    "example_img_with_mask_above = cv2.bitwise_and(example_img, example_img, mask=mask_above)\n",
    "\n",
    "# Plot the mask and example image with the mask applied\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 8))\n",
    "\n",
    "# Mask for the above region\n",
    "axs[0].imshow(mask_above, cmap='gray', extent=[0, img_width, img_height, 0])\n",
    "axs[0].set_title(\"Mask for Region Above the Line\")\n",
    "axs[0].set_xlabel(\"X Coordinate (Width)\")\n",
    "axs[0].set_ylabel(\"Y Coordinate (Height)\")\n",
    "\n",
    "# Example image with mask applied\n",
    "axs[1].imshow(cv2.cvtColor(example_img_with_mask_above, cv2.COLOR_BGR2RGB))\n",
    "axs[1].set_title(\"Example Image with Above Mask Applied\")\n",
    "axs[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the deduction\n",
    "deducted_mask_above = cv2.bitwise_and(mask_above, cv2.bitwise_not(mask_approx))\n",
    "\n",
    "# Plot the masks side by side\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 8))\n",
    "\n",
    "# Original `another_mask`\n",
    "axs[0].imshow(mask_above, cmap='gray', extent=[0, img_width, img_height, 0])\n",
    "axs[0].set_title(\"Original Mask\")\n",
    "axs[0].set_xlabel(\"X Coordinate (Width)\")\n",
    "axs[0].set_ylabel(\"Y Coordinate (Height)\")\n",
    "\n",
    "# `mask_approx`\n",
    "axs[1].imshow(mask_approx, cmap='gray', extent=[0, img_width, img_height, 0])\n",
    "axs[1].set_title(\"Mask to Deduct (mask_approx)\")\n",
    "axs[1].set_xlabel(\"X Coordinate (Width)\")\n",
    "axs[1].set_ylabel(\"Y Coordinate (Height)\")\n",
    "\n",
    "# Resulting `deducted_mask`\n",
    "axs[2].imshow(deducted_mask_above, cmap='gray', extent=[0, img_width, img_height, 0])\n",
    "axs[2].set_title(\"Resulting Mask After Deduction\")\n",
    "axs[2].set_xlabel(\"X Coordinate (Width)\")\n",
    "axs[2].set_ylabel(\"Y Coordinate (Height)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the resulting mask for later use or inspection\n",
    "output_path = os.path.join(folder, \"deducted_mask.png\")\n",
    "cv2.imwrite(output_path, deducted_mask_above)\n",
    "print(f\"Deducted mask saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find contours in the mask\n",
    "contours, _ = cv2.findContours(deducted_mask_above, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Create a blank mask\n",
    "filled_mask_above = np.zeros_like(deducted_mask_above)\n",
    "\n",
    "# Fill the contours\n",
    "cv2.drawContours(filled_mask_above, contours, -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "# Plot the original mask and the filled mask side by side\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 8))\n",
    "\n",
    "# Original mask\n",
    "axs[0].imshow(deducted_mask_above, cmap='gray', extent=[0, img_width, img_height, 0])\n",
    "axs[0].set_title(\"Original Mask with Holes\")\n",
    "axs[0].set_xlabel(\"X Coordinate (Width)\")\n",
    "axs[0].set_ylabel(\"Y Coordinate (Height)\")\n",
    "\n",
    "# Filled mask\n",
    "axs[1].imshow(filled_mask_above, cmap='gray', extent=[0, img_width, img_height, 0])\n",
    "axs[1].set_title(\"Mask with Holes Filled\")\n",
    "axs[1].set_xlabel(\"X Coordinate (Width)\")\n",
    "axs[1].set_ylabel(\"Y Coordinate (Height)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the filled mask\n",
    "output_path = os.path.join(folder, \"filled_mask_above.png\")\n",
    "cv2.imwrite(output_path, filled_mask_above)\n",
    "print(f\"Filled mask saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a blank mask for the below region\n",
    "mask_below = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "\n",
    "# Define the region below the line between `left_point` and `right_point`\n",
    "polygon_below = np.array([[0, img_height], [img_width, img_height], right_point, left_point], dtype=np.int32)\n",
    "\n",
    "# Draw the polygon on the mask\n",
    "cv2.fillPoly(mask_below, [polygon_below], 255)\n",
    "\n",
    "# Apply the mask to the example image\n",
    "example_img_with_mask_below = cv2.bitwise_and(example_img, example_img, mask=mask_below)\n",
    "\n",
    "# Plot the mask and example image with the mask applied\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 8))\n",
    "\n",
    "# Mask for the below region\n",
    "axs[0].imshow(mask_below, cmap='gray', extent=[0, img_width, img_height, 0])\n",
    "axs[0].set_title(\"Mask for Region Below the Line\")\n",
    "axs[0].set_xlabel(\"X Coordinate (Width)\")\n",
    "axs[0].set_ylabel(\"Y Coordinate (Height)\")\n",
    "\n",
    "# Example image with mask applied\n",
    "axs[1].imshow(cv2.cvtColor(example_img_with_mask_below, cv2.COLOR_BGR2RGB))\n",
    "axs[1].set_title(\"Example Image with Below Mask Applied\")\n",
    "axs[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the deduction\n",
    "mask_inv = cv2.bitwise_not(mask_below)\n",
    "deducted_mask_below = cv2.bitwise_or(mask_approx, cv2.bitwise_not(mask_inv))\n",
    "\n",
    "# Plot the masks side by side\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 8))\n",
    "\n",
    "# Original `another_mask`\n",
    "axs[0].imshow(mask_below, cmap='gray', extent=[0, img_width, img_height, 0])\n",
    "axs[0].set_title(\"Original Mask\")\n",
    "axs[0].set_xlabel(\"X Coordinate (Width)\")\n",
    "axs[0].set_ylabel(\"Y Coordinate (Height)\")\n",
    "\n",
    "# `mask_approx`\n",
    "axs[1].imshow(mask_approx, cmap='gray', extent=[0, img_width, img_height, 0])\n",
    "axs[1].set_title(\"Mask to Deduct (mask_approx)\")\n",
    "axs[1].set_xlabel(\"X Coordinate (Width)\")\n",
    "axs[1].set_ylabel(\"Y Coordinate (Height)\")\n",
    "\n",
    "# Resulting `deducted_mask`\n",
    "axs[2].imshow(deducted_mask_below, cmap='gray', extent=[0, img_width, img_height, 0])\n",
    "axs[2].set_title(\"Resulting Mask After Deduction\")\n",
    "axs[2].set_xlabel(\"X Coordinate (Width)\")\n",
    "axs[2].set_ylabel(\"Y Coordinate (Height)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the resulting mask for later use or inspection\n",
    "output_path = os.path.join(folder, \"deducted_mask_below.png\")\n",
    "cv2.imwrite(output_path, deducted_mask_below)\n",
    "print(f\"Deducted mask saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find contours in the mask\n",
    "contours, _ = cv2.findContours(deducted_mask_below, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Create a blank mask\n",
    "filled_mask_below = np.zeros_like(deducted_mask_below)\n",
    "\n",
    "# Fill the contours\n",
    "cv2.drawContours(filled_mask_below, contours, -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "# Plot the original mask and the filled mask side by side\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 8))\n",
    "\n",
    "# Original mask\n",
    "axs[0].imshow(deducted_mask_below, cmap='gray', extent=[0, img_width, img_height, 0])\n",
    "axs[0].set_title(\"Original Mask with Holes\")\n",
    "axs[0].set_xlabel(\"X Coordinate (Width)\")\n",
    "axs[0].set_ylabel(\"Y Coordinate (Height)\")\n",
    "\n",
    "# Filled mask\n",
    "axs[1].imshow(filled_mask_below, cmap='gray', extent=[0, img_width, img_height, 0])\n",
    "axs[1].set_title(\"Mask with Holes Filled\")\n",
    "axs[1].set_xlabel(\"X Coordinate (Width)\")\n",
    "axs[1].set_ylabel(\"Y Coordinate (Height)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the filled mask\n",
    "output_path = os.path.join(folder, \"filled_mask_below.png\")\n",
    "cv2.imwrite(output_path, filled_mask_below)\n",
    "print(f\"Filled mask saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new mask by deducting the overlap between mask_above and mask_outside\n",
    "mask_above_deduction = cv2.bitwise_and(mask_above, cv2.bitwise_not(mask_outside))\n",
    "\n",
    "# Apply the deducted mask to the example image\n",
    "example_img_with_mask_above_deduction = cv2.bitwise_and(example_img, example_img, mask=mask_above_deduction)\n",
    "\n",
    "# Plot the original mask_above, mask_outside, and the result of the deduction\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Original mask_above\n",
    "axs[0].imshow(mask_above, cmap='gray', extent=[0, img_width, img_height, 0])\n",
    "axs[0].set_title(\"Original Mask Above\")\n",
    "axs[0].set_xlabel(\"X Coordinate (Width)\")\n",
    "axs[0].set_ylabel(\"Y Coordinate (Height)\")\n",
    "\n",
    "# mask_outside (triangular areas)\n",
    "axs[1].imshow(mask_outside, cmap='gray', extent=[0, img_width, img_height, 0])\n",
    "axs[1].set_title(\"Mask Outside (Triangular Areas)\")\n",
    "axs[1].set_xlabel(\"X Coordinate (Width)\")\n",
    "\n",
    "# Resulting mask_above_deduction\n",
    "axs[2].imshow(mask_above_deduction, cmap='gray', extent=[0, img_width, img_height, 0])\n",
    "axs[2].set_title(\"Mask Above with Outside Deducted\")\n",
    "axs[2].set_xlabel(\"X Coordinate (Width)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot the example image with the deducted mask applied\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cv2.cvtColor(example_img_with_mask_above_deduction, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Example Image with Deducted Mask Above Applied\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_inside = cv2.bitwise_not(deducted_mask_outside)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cv2.cvtColor(mask_inside, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Example Image with Deducted Mask Above Applied\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = {\n",
    "    'filled_mask_below': filled_mask_below,\n",
    "    'filled_mask_above': filled_mask_above,\n",
    "    'deducted_mask_outside': deducted_mask_outside,\n",
    "    'mask_inside': mask_inside\n",
    "}\n",
    "\n",
    "\n",
    "output_folder = r'D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\batch\\output_grayscale_gaussian'\n",
    "\n",
    "for mask_name, mask in masks.items():\n",
    "    # Save as PNG image\n",
    "    mask_filename = os.path.join(output_folder, f\"{mask_name}.png\")\n",
    "    cv2.imwrite(mask_filename, mask)\n",
    "    print(f\"Mask '{mask_name}' saved to {mask_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths and parameters\n",
    "image_folder = r''\n",
    "output_folder = r'D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\batch\\output_grayscale_gaussian'\n",
    "\n",
    "# Masks dictionary containing mask names and paths\n",
    "masks = {\n",
    "    \"mask_above\": os.path.join(output_folder, \"mask_above.png\"),\n",
    "    \"mask_below\": os.path.join(output_folder, \"mask_below.png\"),\n",
    "    \"mask_outside\": os.path.join(output_folder, \"mask_outside.png\"),\n",
    "    \"mask_above_deduction\": os.path.join(output_folder, \"mask_above_deduction.png\"),\n",
    "    \"mask_approx\": os.path.join(output_folder, \"mask_approx.png\"),\n",
    "}\n",
    "\n",
    "# Get sorted list of images to process\n",
    "images_to_process = sorted([img for img in os.listdir(image_folder) if img.endswith(\".jpg\")])\n",
    "\n",
    "# Iterate over each mask dynamically\n",
    "for mask_name, mask_path in tqdm(masks.items(), desc=\"Processing Masks\"):\n",
    "    # Load the mask\n",
    "    if not os.path.exists(mask_path):\n",
    "        print(f\"Mask not found: {mask_path}\")\n",
    "        continue\n",
    "    \n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Create output folder for each mask\n",
    "    mask_output_folder = os.path.join(output_folder, f\"masked_images_{mask_name}\")\n",
    "    os.makedirs(mask_output_folder, exist_ok=True)\n",
    "    \n",
    "    # Apply the mask to all images\n",
    "    for image_name in tqdm(images_to_process, desc=f\"Applying {mask_name}\"):\n",
    "        image_path = os.path.join(image_folder, image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        # Resize the mask if necessary\n",
    "        if mask.shape != image.shape[:2]:\n",
    "            mask_resized = cv2.resize(mask, (image.shape[1], image.shape[0]))\n",
    "        else:\n",
    "            mask_resized = mask\n",
    "        \n",
    "        # Apply the mask to the image\n",
    "        masked_image = cv2.bitwise_and(image, image, mask=mask_resized)\n",
    "        \n",
    "        # Save the masked image\n",
    "        output_image_path = os.path.join(mask_output_folder, f\"masked_{image_name}\")\n",
    "        cv2.imwrite(output_image_path, masked_image)\n",
    "    \n",
    "    print(f\"Finished applying {mask_name}. Results saved to {mask_output_folder}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paind_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
