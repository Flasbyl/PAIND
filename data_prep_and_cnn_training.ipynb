{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep & Sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def remove_string_from_filenames(directory, string_to_remove):\n",
    "    \"\"\"\n",
    "    Removes a specific string from the beginning of .jpg file names in the given directory.\n",
    "    \n",
    "    Parameters:\n",
    "    - directory (str): Path to the directory containing the files.\n",
    "    - string_to_remove (str): The string to be removed from the start of file names.\n",
    "    \"\"\"\n",
    "    for filename in os.listdir(directory):\n",
    "        # Check if the file has a .jpg extension\n",
    "        if filename.endswith(\".jpg\") and filename.startswith(string_to_remove):\n",
    "            # Remove the specified string from the start of the filename\n",
    "            new_name = filename[len(string_to_remove):]\n",
    "            # Construct full file paths\n",
    "            old_path = os.path.join(directory, filename)\n",
    "            new_path = os.path.join(directory, new_name)\n",
    "            # Rename the file\n",
    "            os.rename(old_path, new_path)\n",
    "            print(f\"Renamed: {filename} -> {new_name}\")\n",
    "\"\"\"\n",
    "# Specify the directory and string to remove\n",
    "directory_path = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\labeled_regions\\inside\"  # Replace with your directory path\n",
    "string_to_remove = \"mask_inside_\"      # Replace with the string to remove\n",
    "\n",
    "# Call the function\n",
    "remove_string_from_filenames(directory_path, string_to_remove)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "opc_data_path = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\opcua\\opc-ua_data.csv\"\n",
    "webcam_folder = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\labeled_regions\\inside_downscaled\"\n",
    "zed2_folder = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\zed2\"\n",
    "\n",
    "# Load and preprocess the OPC data\n",
    "def load_opc_data(opc_path, custom_headers= [\n",
    "    \"Timestamp\", \"Parameter1\", \"Parameter2\", \"Parameter3\", \"Parameter4\", \n",
    "    \"Parameter5\", \"Parameter6\", \"Parameter7\", \"Parameter8\", \"Parameter9\", \n",
    "    \"Flag1\", \"Flag2\", \"Flag3\", \"Flag4\", \"Flag5\", \"Flag6\", \"Parameter10\", \n",
    "    \"Flag7\", \"Flag8\", \"Flag9\", \"Flag10\", \"Flag11\", \"Parameter11\"\n",
    "]):\n",
    "    try:\n",
    "        # Read the file, specifying ';' as the delimiter and without headers\n",
    "        opc_df = pd.read_csv(opc_path, sep=';', header=None)\n",
    "\n",
    "        # Assign custom headers to the DataFrame\n",
    "        opc_df.columns = custom_headers\n",
    "\n",
    "        print(f\"Preprocessed OPC data with {len(custom_headers)} custom headers.\")\n",
    "        return opc_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error preprocessing OPC data: {e}\")\n",
    "        return None\n",
    "# Load image file names into a DataFrame\n",
    "def load_image_data(image_folder, camera_name):\n",
    "    try:\n",
    "        image_files = sorted([f for f in os.listdir(image_folder) if f.endswith(\".jpg\")])\n",
    "        camera_df = pd.DataFrame(image_files, columns=[\"image_name\"])\n",
    "        camera_df[\"camera\"] = camera_name\n",
    "        print(f\"Loaded {len(camera_df)} images for {camera_name}.\")\n",
    "        return camera_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading images for {camera_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load OPC data\n",
    "opc_df = load_opc_data(opc_data_path)\n",
    "\n",
    "# Load webcam images into a DataFrame\n",
    "webcam_df = load_image_data(webcam_folder, \"webcam\")\n",
    "\n",
    "# Load Zed2 images into a DataFrame\n",
    "zed2_df = load_image_data(zed2_folder, \"zed2\")\n",
    "\n",
    "# Display summary of loaded data\n",
    "if opc_df is not None:\n",
    "    print(\"OPC DataFrame Head:\")\n",
    "    print(opc_df)\n",
    "\n",
    "if webcam_df is not None:\n",
    "    print(\"Webcam DataFrame Head:\")\n",
    "    print(webcam_df)\n",
    "\n",
    "if zed2_df is not None:\n",
    "    print(\"Zed2 DataFrame Head:\")\n",
    "    print(zed2_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and process timestamps from webcam images\n",
    "webcam_df[\"Timestamp\"] = webcam_df[\"image_name\"].str.extract(r\"(\\d{8}_\\d{9})\")\n",
    "webcam_df[\"Timestamp\"] = pd.to_datetime(webcam_df[\"Timestamp\"], format=\"%Y%m%d_%H%M%S%f\")\n",
    "\n",
    "# Extract and process timestamps from ZED2 images\n",
    "zed2_df[\"Timestamp\"] = zed2_df[\"image_name\"].str.extract(r\"(\\d{8}_\\d{9})\")\n",
    "zed2_df[\"Timestamp\"] = pd.to_datetime(zed2_df[\"Timestamp\"], format=\"%Y%m%d_%H%M%S%f\")\n",
    "\n",
    "# Combine the webcam and ZED2 data into a single DataFrame\n",
    "images_df = pd.concat([webcam_df, zed2_df], ignore_index=True)\n",
    "\n",
    "# Process OPC DataFrame timestamps\n",
    "opc_df[\"Timestamp\"] = pd.to_datetime(opc_df[\"Timestamp\"], format=\"%Y%m%d %H:%M:%S.%f\")\n",
    "\n",
    "# Save the processed DataFrames (optional)\n",
    "webcam_df.to_csv(\"processed_webcam.csv\", index=False)\n",
    "zed2_df.to_csv(\"processed_zed2.csv\", index=False)\n",
    "images_df.to_csv(\"processed_images.csv\", index=False)\n",
    "opc_df.to_csv(\"processed_opc.csv\", index=False)\n",
    "\n",
    "# Display processed DataFrames for verification\n",
    "print(\"Processed Webcam DataFrame:\")\n",
    "print(webcam_df.head())\n",
    "\n",
    "print(\"\\nProcessed ZED2 DataFrame:\")\n",
    "print(zed2_df.head())\n",
    "\n",
    "print(\"\\nProcessed Combined Images DataFrame:\")\n",
    "print(images_df.head())\n",
    "\n",
    "print(\"\\nProcessed OPC DataFrame:\")\n",
    "print(opc_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def truncate_timestamps(opc_df, webcam_df):\n",
    "    \"\"\"\n",
    "    Truncate the Timestamp column in all DataFrames to seconds.\n",
    "    This ensures more overlaps between the DataFrames during synchronization.\n",
    "    \"\"\"\n",
    "    for df in [opc_df, webcam_df]:\n",
    "        df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"]).dt.floor(\"s\")\n",
    "    return opc_df, webcam_df\n",
    "\n",
    "def aggregate_opc_data(opc_df):\n",
    "    \"\"\"\n",
    "    Aggregate OPC DataFrame to have a single entry per Timestamp by calculating averages.\n",
    "    \"\"\"\n",
    "    # Drop the SecondaryIndex as it's no longer needed\n",
    "    opc_df = opc_df.drop(columns=[\"SecondaryIndex\"], errors=\"ignore\")\n",
    "\n",
    "    # Group by Timestamp and calculate the mean for numerical columns\n",
    "    aggregated_opc_df = opc_df.groupby(\"Timestamp\").mean().reset_index()\n",
    "\n",
    "    return aggregated_opc_df\n",
    "\n",
    "def synchronize_opc_to_webcam(opc_df, webcam_df):\n",
    "    \"\"\"\n",
    "    Ensure OPC DataFrame matches Webcam DataFrame timestamps.\n",
    "    Fill missing OPC data with NaN for unmatched timestamps in Webcam DataFrame.\n",
    "    \"\"\"\n",
    "    # Merge webcam timestamps with OPC data\n",
    "    synchronized_df = pd.merge(\n",
    "        webcam_df[[\"Timestamp\"]],  # Use only timestamps from webcam\n",
    "        opc_df,\n",
    "        on=\"Timestamp\",\n",
    "        how=\"left\"  # Keep all webcam timestamps\n",
    "    )\n",
    "    return synchronized_df\n",
    "\n",
    "# Apply truncation to timestamps\n",
    "opc_df, webcam_df = truncate_timestamps(opc_df, webcam_df)\n",
    "\n",
    "# Aggregate OPC data to a single entry per timestamp\n",
    "opc_df = aggregate_opc_data(opc_df)\n",
    "\n",
    "# Synchronize OPC data to match Webcam timestamps\n",
    "opc_synced = synchronize_opc_to_webcam(opc_df, webcam_df)\n",
    "\n",
    "# Debug outputs\n",
    "print(f\"Aggregated OPC DataFrame length: {len(opc_df)}\")\n",
    "print(f\"Synchronized OPC DataFrame length: {len(opc_synced)}\")\n",
    "print(f\"Webcam DataFrame length: {len(webcam_df)}\")\n",
    "print(opc_synced.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Synchronized OPC DataFrame:\")\n",
    "print(opc_synced['Timestamp'])\n",
    "\n",
    "print(\"\\nSynchronized Webcam DataFrame:\")\n",
    "print(webcam_df['Timestamp'])\n",
    "\"\"\"\n",
    "print(\"\\nSynchronized ZED2 DataFrame:\")\n",
    "print(zed2_synced)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop flags and parameters that dont show any changes or are identical to another flag/parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opc_alt = opc_synced.drop(columns=['Parameter1', 'Parameter2', 'Parameter4', 'Parameter5', 'Parameter9', 'Parameter11', 'Flag1', 'Flag7', 'Flag8', 'Flag9', 'Flag11'])\n",
    "print(opc_alt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "opc_alt.to_csv(r'C:\\Users\\Public\\Desktop\\opc_alt.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display remaining opc data visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_opc_data(opc_df):\n",
    "    \"\"\"\n",
    "    Visualize each column in the OPC data with individual line plots.\n",
    "    \n",
    "    Parameters:\n",
    "    - opc_df: DataFrame containing the OPC data\n",
    "    \"\"\"\n",
    "    # Drop the 'Timestamp' column to only plot the numerical/categorical data\n",
    "    columns_to_plot = opc_df.drop(columns=['Timestamp'])\n",
    "    \n",
    "    # Create a figure with subplots for each column\n",
    "    num_columns = len(columns_to_plot.columns)\n",
    "    fig, axs = plt.subplots(num_columns, 1, figsize=(12, 4 * num_columns), sharex=True)\n",
    "    \n",
    "    if num_columns == 1:\n",
    "        axs = [axs]  # Ensure axs is iterable if there's only one column\n",
    "\n",
    "    # Iterate through the columns and plot each\n",
    "    for i, column in enumerate(columns_to_plot.columns):\n",
    "        axs[i].plot(opc_df['Timestamp'], columns_to_plot[column], label=column, linewidth=0.8)\n",
    "        axs[i].set_title(f\"{column} Over Time\", fontsize=12)\n",
    "        axs[i].set_ylabel(column)\n",
    "        axs[i].grid(True)\n",
    "        axs[i].legend(loc='upper right')\n",
    "\n",
    "    # Set shared X-axis label\n",
    "    axs[-1].set_xlabel(\"Timestamp\")\n",
    "    \n",
    "    # Adjust layout for better spacing\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example Usage:\n",
    "visualize_opc_data(opc_alt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare opc data for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "opc_cleaned = opc_alt\n",
    "scaler = MinMaxScaler()\n",
    "opc_cleaned.iloc[:, 1:] = scaler.fit_transform(opc_cleaned.iloc[:, 1:])\n",
    "#print(opc_cleaned)\n",
    "#visualize_opc_data(opc_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "opc_cleaned['Timestamp'] = pd.to_datetime(opc_cleaned['Timestamp'])\n",
    "opc_cleaned['Seconds'] = opc_cleaned['Timestamp'].dt.hour * 3600 + \\\n",
    "                         opc_cleaned['Timestamp'].dt.minute * 60 + \\\n",
    "                         opc_cleaned['Timestamp'].dt.second\n",
    "opc_cleaned.drop(columns=[\"Timestamp\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(opc_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 5\n",
    "features = opc_cleaned.iloc[:, 1:].values  # Exclude the seconds column\n",
    "sequences = []\n",
    "for i in range(len(features) - window_size):\n",
    "    sequences.append(features[i:i+window_size])\n",
    "\n",
    "opc_sequences = np.array(sequences)  # Shape: (samples, timesteps, features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('opc_sequences.npy', opc_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths\n",
    "output_folder = r\"D:\\PAIND\\DATA\\Processed\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "image_folder = r\"D:\\PAIND\\DATA\\20240527_Data_Prozess_01\\webcam\\labeled_regions\\inside_downscaled\"\n",
    "\n",
    "# Fixed image size for CNN\n",
    "IMAGE_SIZE = (224, 126)\n",
    "\n",
    "# Load the synchronized webcam DataFrame\n",
    "#webcam_df = webcam_synced\n",
    "\n",
    "# Parameters for batch processing\n",
    "batch_size = 1000  # Number of images to process in one batch\n",
    "num_batches = (len(webcam_df) // batch_size) + 1\n",
    "\n",
    "# Process images in batches\n",
    "for batch_idx in range(num_batches):\n",
    "    start_idx = batch_idx * batch_size\n",
    "    end_idx = min((batch_idx + 1) * batch_size, len(webcam_df))\n",
    "    batch_df = webcam_df.iloc[start_idx:end_idx]\n",
    "\n",
    "    processed_images = []  # Placeholder for the current batch\n",
    "\n",
    "    for _, row in tqdm(batch_df.iterrows(), total=len(batch_df), desc=f\"Processing Batch {batch_idx + 1}/{num_batches}\"):\n",
    "        image_path = os.path.join(image_folder, row[\"image_name\"])\n",
    "        \n",
    "        # Load the image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Image not found: {image_path}. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Resize and normalize the image\n",
    "        image_resized = cv2.resize(image, IMAGE_SIZE)\n",
    "        image_normalized = image_resized / 255.0  # Normalize to [0, 1]\n",
    "        \n",
    "        processed_images.append(image_normalized)\n",
    "\n",
    "    # Convert list to NumPy array and save the batch\n",
    "    batch_array = np.array(processed_images)\n",
    "    batch_output_path = os.path.join(output_folder, f\"processed_images_batch_{batch_idx + 1}.npy\")\n",
    "    np.save(batch_output_path, batch_array)\n",
    "\n",
    "    print(f\"Processed batch {batch_idx + 1}/{num_batches} and saved to {batch_output_path}.\")\n",
    "\n",
    "print(\"All batches processed and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge opc data & images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Path to one of the processed image batches\n",
    "npy_file_path = r\"D:\\PAIND\\DATA\\Processed\\processed_images_batch_2.npy\"\n",
    "\n",
    "# Load the .npy file\n",
    "try:\n",
    "    loaded_data = np.load(npy_file_path)\n",
    "    # Check the shape and content of the loaded data\n",
    "    print(f\"Loaded data shape: {loaded_data.shape}\")\n",
    "    print(f\"Sample data (first entry):\\n{loaded_data[0]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading .npy file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "processed_images_folder = r\"D:\\PAIND\\DATA\\Processed\"  # Folder containing processed image batches\n",
    "output_folder = r\"D:\\PAIND\\DATA\\Processed\"\n",
    "\n",
    "# Load synchronized OPC DataFrame\n",
    "opc_df = opc_cleaned  # Ensure this is synchronized and sorted\n",
    "\n",
    "# Placeholder for merged results\n",
    "merged_batches = []\n",
    "\n",
    "# List batch files\n",
    "batch_files = sorted([file for file in os.listdir(processed_images_folder) if file.startswith(\"processed_images_batch_\") and file.endswith(\".npy\")])\n",
    "\n",
    "# Check batch size from the first `.npy` file\n",
    "batch_size = np.load(os.path.join(processed_images_folder, batch_files[0])).shape[0]\n",
    "\n",
    "# Process batches based on order\n",
    "for batch_idx, batch_file in enumerate(batch_files):\n",
    "    # Load the processed image batch\n",
    "    batch_path = os.path.join(processed_images_folder, batch_file)\n",
    "    image_batch = np.load(batch_path)\n",
    "\n",
    "    # Determine the slice of OPC DataFrame corresponding to this batch\n",
    "    start_idx = batch_idx * batch_size\n",
    "    end_idx = start_idx + len(image_batch)  # Account for last batch which may be smaller\n",
    "    opc_batch = opc_df.iloc[start_idx:end_idx].reset_index(drop=True)\n",
    "\n",
    "    # Verify alignment\n",
    "    try:\n",
    "        assert len(opc_batch) == len(image_batch), f\"Mismatch in batch {batch_idx + 1}!\"\n",
    "        # Append the merged batch to results\n",
    "        merged_batches.append((opc_batch, image_batch))\n",
    "    except:\n",
    "        print('exception at {batch_idx}')\n",
    "        break\n",
    "\n",
    "# Save merged data and images\n",
    "for batch_idx, (opc_batch, image_batch) in enumerate(merged_batches):\n",
    "    try:\n",
    "        # Save the merged OPC batch as a CSV\n",
    "        merged_csv_path = os.path.join(output_folder, f\"merged_opc_data_batch_{batch_idx + 1}.csv\")\n",
    "        opc_batch.to_csv(merged_csv_path, index=False)\n",
    "        \n",
    "        # Save the corresponding image batch\n",
    "        merged_image_path = os.path.join(output_folder, f\"merged_images_batch_{batch_idx + 1}.npy\")\n",
    "        np.save(merged_image_path, image_batch)\n",
    "    except:\n",
    "        print('exception at {batch_idx}')\n",
    "        break\n",
    "\n",
    "print(\"All batches merged and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define split ratios\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "# Ensure the ratios sum to 1\n",
    "assert train_ratio + val_ratio + test_ratio == 1, \"Ratios must sum to 1!\"\n",
    "\n",
    "# Determine split indices\n",
    "num_batches = len(merged_batches)\n",
    "train_end = int(train_ratio * num_batches)\n",
    "val_end = int((train_ratio + val_ratio) * num_batches)\n",
    "\n",
    "# Split the merged_batches\n",
    "train_batches = merged_batches[:train_end]\n",
    "val_batches = merged_batches[train_end:val_end]\n",
    "test_batches = merged_batches[val_end:]\n",
    "\n",
    "# Save the splits\n",
    "output_folder = r\"D:\\PAIND\\DATA\\Processed\"\n",
    "\n",
    "def save_split_batches(split_batches, split_name):\n",
    "    os.makedirs(os.path.join(output_folder, split_name), exist_ok=True)\n",
    "    for idx, (merged_batch, image_batch) in enumerate(split_batches):\n",
    "        # Save the merged batch as a CSV\n",
    "        merged_csv_path = os.path.join(output_folder, split_name, f\"{split_name}_data_batch_{idx + 1}.csv\")\n",
    "        merged_batch.to_csv(merged_csv_path, index=False)\n",
    "\n",
    "        # Save the corresponding image batch\n",
    "        merged_image_path = os.path.join(output_folder, split_name, f\"{split_name}_images_batch_{idx + 1}.npy\")\n",
    "        np.save(merged_image_path, image_batch)\n",
    "\n",
    "# Save each split\n",
    "save_split_batches(train_batches, \"train\")\n",
    "save_split_batches(val_batches, \"val\")\n",
    "save_split_batches(test_batches, \"test\")\n",
    "\n",
    "# Print summary\n",
    "print(f\"Training Batches: {len(train_batches)}\")\n",
    "print(f\"Validation Batches: {len(val_batches)}\")\n",
    "print(f\"Test Batches: {len(test_batches)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define the CNN model\n",
    "def create_cnn(input_shape, output_size):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(output_size, activation='linear')  \n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Initialize model\n",
    "input_shape = (126, 224, 3)  \n",
    "output_size = 12  #\n",
    "cnn_model = create_cnn(input_shape, output_size)\n",
    "\n",
    "# Training function\n",
    "def train_cnn_on_batches(model, train_folder, val_folder, epochs, batch_size):\n",
    "    \"\"\"\n",
    "    Train the CNN model batch-by-batch across epochs.\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        train_batches = sorted([f for f in os.listdir(train_folder) if f.startswith(\"train_data_batch\")])\n",
    "\n",
    "        for batch_file in train_batches:\n",
    "            # Load batch data\n",
    "            batch_idx = int(batch_file.split(\"_\")[-1].split(\".\")[0])\n",
    "            train_data = pd.read_csv(os.path.join(train_folder, batch_file))\n",
    "            train_images = np.load(os.path.join(train_folder, f\"train_images_batch_{batch_idx}.npy\"))\n",
    "\n",
    "            # Prepare training inputs and outputs\n",
    "            x_train = train_images  # Image batch\n",
    "            y_train = train_data.iloc[:, 1:].values  # OPC features (drop timestamp)\n",
    "\n",
    "            # Train the model on this batch\n",
    "            model.fit(x_train, y_train, batch_size=batch_size, verbose=1)\n",
    "\n",
    "        # Validate after every epoch\n",
    "        validate_cnn_on_batches(model, val_folder)\n",
    "\n",
    "# Validation function\n",
    "def validate_cnn_on_batches(model, val_folder):\n",
    "    \"\"\"\n",
    "    Validate the CNN model on all validation batches.\n",
    "    \"\"\"\n",
    "    val_batches = sorted([f for f in os.listdir(val_folder) if f.startswith(\"val_data_batch\")])\n",
    "    total_loss, total_mae, total_samples = 0, 0, 0\n",
    "\n",
    "    for batch_file in val_batches:\n",
    "        # Load validation batch\n",
    "        batch_idx = int(batch_file.split(\"_\")[-1].split(\".\")[0])\n",
    "        val_data = pd.read_csv(os.path.join(val_folder, batch_file))\n",
    "        val_images = np.load(os.path.join(val_folder, f\"val_images_batch_{batch_idx}.npy\"))\n",
    "\n",
    "        # Prepare validation inputs and outputs\n",
    "        x_val = val_images\n",
    "        y_val = val_data.iloc[:, 1:].values\n",
    "\n",
    "        # Evaluate this batch\n",
    "        loss, mae = model.evaluate(x_val, y_val, verbose=1)\n",
    "        batch_size = len(val_data)\n",
    "        total_loss += loss * batch_size\n",
    "        total_mae += mae * batch_size\n",
    "        total_samples += batch_size\n",
    "\n",
    "    # Compute final metrics\n",
    "    final_loss = total_loss / total_samples\n",
    "    final_mae = total_mae / total_samples\n",
    "    print(f\"Validation Loss: {final_loss:.4f}, Validation MAE: {final_mae:.4f}\")\n",
    "\n",
    "# Paths\n",
    "train_folder = r\"D:\\PAIND\\DATA\\Processed\\train\"\n",
    "val_folder = r\"D:\\PAIND\\DATA\\Processed\\val\"\n",
    "test_folder = r\"D:\\PAIND\\DATA\\Processed\\test\"\n",
    "\n",
    "# Train the model\n",
    "train_cnn_on_batches(cnn_model, train_folder, val_folder, epochs=50, batch_size=32)\n",
    "\n",
    "# Save the trained model\n",
    "model_path = r\"D:\\PAIND\\DATA\\Processed\\cnn.keras\"\n",
    "cnn_model.save(model_path)\n",
    "print(f\"Model saved to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "avg. max RAM used for whole script: 54GB +/- 1GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the trained model\n",
    "trained_model = load_model(model_path)\n",
    "\n",
    "# Get test batch files\n",
    "batch_files = sorted([file for file in os.listdir(test_folder) if file.endswith(\".csv\")])\n",
    "\n",
    "# Iterate over test batches\n",
    "for batch_file in batch_files:\n",
    "    # Load the test data CSV and corresponding image .npy\n",
    "    batch_csv_path = os.path.join(test_folder, batch_file)\n",
    "    batch_data = pd.read_csv(batch_csv_path)\n",
    "\n",
    "    # Replace \"data\" with \"images\" to find the correct .npy file for images\n",
    "    image_batch_path = batch_csv_path.replace(\"_data_\", \"_images_\").replace(\".csv\", \".npy\")\n",
    "    x_test = np.load(image_batch_path)  # Load the image batch\n",
    "\n",
    "    # OPC features\n",
    "    y_test = batch_data.iloc[:, 1:].values  # Drop the Timestamp column\n",
    "\n",
    "    # Evaluate on this batch\n",
    "    results = trained_model.evaluate(x_test, y_test, verbose=1)\n",
    "    print(f\"Batch {batch_file}: Loss = {results[0]}, MAE = {results[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test batch\n",
    "predictions = trained_model.predict(x_test)\n",
    "\n",
    "# Save predictions alongside original OPC data\n",
    "predictions_df = pd.DataFrame(predictions, columns=[f\"Predicted_{col}\" for col in batch_data.columns[1:]])\n",
    "results_df = pd.concat([batch_data, predictions_df], axis=1)\n",
    "\n",
    "# Save to a file\n",
    "output_predictions_path = r\"D:\\PAIND\\DATA\\Processed\\predictions.csv\"\n",
    "results_df.to_csv(output_predictions_path, index=False)\n",
    "print(f\"Predictions saved to: {output_predictions_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_opc_data(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "test_folder = r\"D:\\PAIND\\DATA\\Processed\\test\"\n",
    "\n",
    "# Load the trained model\n",
    "from keras.models import load_model\n",
    "model_path = r\"D:\\PAIND\\DATA\\Processed\\cnn.keras\"\n",
    "trained_model = load_model(model_path)\n",
    "\n",
    "# Initialize lists to store results\n",
    "losses = []\n",
    "maes = []\n",
    "batch_indices = []\n",
    "\n",
    "# Get test batch files\n",
    "batch_files = sorted([file for file in os.listdir(test_folder) if file.endswith(\".csv\")])\n",
    "\n",
    "# Iterate over test batches and collect loss and MAE\n",
    "for batch_file in batch_files:\n",
    "    # Load the test data CSV and corresponding image .npy\n",
    "    batch_csv_path = os.path.join(test_folder, batch_file)\n",
    "    batch_data = pd.read_csv(batch_csv_path)\n",
    "    image_batch_path = batch_csv_path.replace(\"_data_\", \"_images_\").replace(\".csv\", \".npy\")\n",
    "    x_test = np.load(image_batch_path)  # Load the image batch\n",
    "    y_test = batch_data.iloc[:, 1:].values  # Drop the Timestamp column\n",
    "\n",
    "    # Evaluate on this batch\n",
    "    loss, mae = trained_model.evaluate(x_test, y_test, verbose=0)  # Suppress verbose output\n",
    "    losses.append(loss)\n",
    "    maes.append(mae)\n",
    "    batch_indices.append(batch_file.split(\"_\")[-1].replace(\".csv\", \"\"))  # Extract batch index\n",
    "\n",
    "# Convert batch indices to integers for sorting\n",
    "batch_indices = [int(idx) for idx in batch_indices]\n",
    "\n",
    "# Plot Loss and MAE\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(batch_indices, losses, marker=\"o\", label=\"Loss\")\n",
    "plt.title(\"Loss and MAE Across Test Batches\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Plot MAE\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(batch_indices, maes, marker=\"o\", label=\"MAE\", color=\"orange\")\n",
    "plt.xlabel(\"Batch Index\")\n",
    "plt.ylabel(\"Mean Absolute Error (MAE)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# File path to your loss and MAE data\n",
    "file_path = r\"D:\\PAIND\\src\\loss_mae.txt\"\n",
    "\n",
    "def parse_loss_mae_file(file_path):\n",
    "    \"\"\"\n",
    "    Parse the loss and MAE file to extract values for each epoch.\n",
    "    \"\"\"\n",
    "    # Regular expression to capture loss and MAE values\n",
    "    batch_pattern = re.compile(r\"loss: ([\\d.]+) - mae: ([\\d.]+)\")\n",
    "    validation_pattern = re.compile(r\"Validation Loss: ([\\d.]+), Validation MAE: ([\\d.]+)\")\n",
    "    \n",
    "    epoch_losses, epoch_maes, val_losses, val_maes = [], [], [], []\n",
    "\n",
    "    # Open the file with error handling for decoding\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n",
    "        for line in file:\n",
    "            # Match batch-level metrics\n",
    "            batch_match = batch_pattern.search(line)\n",
    "            if batch_match:\n",
    "                loss, mae = map(float, batch_match.groups())\n",
    "                epoch_losses.append(loss)\n",
    "                epoch_maes.append(mae)\n",
    "\n",
    "            # Match validation metrics\n",
    "            val_match = validation_pattern.search(line)\n",
    "            if val_match:\n",
    "                val_loss, val_mae = map(float, val_match.groups())\n",
    "                val_losses.append(val_loss)\n",
    "                val_maes.append(val_mae)\n",
    "\n",
    "    return epoch_losses, epoch_maes, val_losses, val_maes\n",
    "\n",
    "# Parse the file\n",
    "epoch_losses, epoch_maes, val_losses, val_maes = parse_loss_mae_file(file_path)\n",
    "\n",
    "# Plot the metrics\n",
    "epochs = range(1, len(val_losses) + 1)\n",
    "\n",
    "# Plot Loss and MAE\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(epochs, val_losses, marker=\"o\", label=\"Loss\")\n",
    "plt.title(\"Loss and MAE Across Test Batches\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Plot MAE\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs, val_maes, marker=\"o\", label=\"MAE\", color=\"orange\")\n",
    "plt.xlabel(\"Batch Index\")\n",
    "plt.ylabel(\"Mean Absolute Error (MAE)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paind_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
